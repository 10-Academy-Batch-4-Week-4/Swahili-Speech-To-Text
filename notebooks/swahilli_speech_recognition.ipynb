{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DB4X_g6ovq6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZP9qdhcRiyUG",
    "outputId": "647279b8-2180-495c-c9b5-444aad8d6f69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part102',\n  'audio': array([-0.01096754, -0.01230842, -0.01015999, ..., -0.21667908,\n         -0.20379573, -0.11009098], dtype=float32)},\n {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part107',\n  'audio': array([-0.00262849, -0.00256155, -0.00178459, ..., -0.2567303 ,\n         -0.21261317,  0.        ], dtype=float32)},\n {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part12',\n  'audio': array([-0.00823285, -0.00249539, -0.00311783, ..., -0.18402188,\n         -0.19362031, -0.11912253], dtype=float32)},\n {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part64',\n  'audio': array([ 0.00796661,  0.0098575 ,  0.0089713 , ...,  0.08651416,\n          0.04152827, -0.00214096], dtype=float32)},\n {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part68',\n  'audio': array([-0.0083479 , -0.0101786 , -0.01026751, ...,  0.0113914 ,\n          0.02161873,  0.        ], dtype=float32)}]"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "rows = []\n",
    "parent_dir = \"../SWH-05-20101106\"\n",
    "files = os.listdir(parent_dir)\n",
    "for f in files:\n",
    "    audio, fs = librosa.load(f\"{parent_dir}/{f}\")\n",
    "    filename = f.split('.')[0]\n",
    "    row = {'filename': filename, 'audio': audio}\n",
    "    rows.append(row)\n",
    "rows[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8NByqTOUhRd",
    "outputId": "928568e2-fc8f-4100-a143-57e344e6cfc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[array([-0.01096754, -0.01230842, -0.01015999, ..., -0.21667908,\n        -0.20379573, -0.11009098], dtype=float32),\n array([-0.00262849, -0.00256155, -0.00178459, ..., -0.2567303 ,\n        -0.21261317,  0.        ], dtype=float32),\n array([-0.00823285, -0.00249539, -0.00311783, ..., -0.18402188,\n        -0.19362031, -0.11912253], dtype=float32),\n array([ 0.00796661,  0.0098575 ,  0.0089713 , ...,  0.08651416,\n         0.04152827, -0.00214096], dtype=float32),\n array([-0.0083479 , -0.0101786 , -0.01026751, ...,  0.0113914 ,\n         0.02161873,  0.        ], dtype=float32)]"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "sample_audios = []\n",
    "for row in rows:\n",
    "    audio = row['audio']\n",
    "    sample_audios.append(audio)\n",
    "sample_audios[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8H6faM08QvZ2"
   },
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv('../metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "bVVnaH5DT6DG",
    "outputId": "3a897f5c-02ae-4bd3-efc6-63bad140ca2c"
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>transcription</th>\n      <th>filepath</th>\n      <th>sample_rate</th>\n      <th>duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n      <td>rais wa tanzania jakaya mrisho kikwete</td>\n      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n      <td>16000</td>\n      <td>3.14</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n      <td>16000</td>\n      <td>3.10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n      <td>16000</td>\n      <td>3.65</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n      <td>16000</td>\n      <td>3.90</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n      <td>16000</td>\n      <td>2.94</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                            filename  \\\n0  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n1  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n2  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n3  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n4  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n\n                                       transcription  \\\n0             rais wa tanzania jakaya mrisho kikwete   \n1  yanayo andaliwa nami pendo pondo idhaa ya kisw...   \n2  inayokutangazia moja kwa moja kutoka jijini da...   \n3  juma hili bara la afrika limeshuhudia raia wa ...   \n4    wakipiga kura ya maoni ilikufanya mabadiliko ya   \n\n                                            filepath  sample_rate  duration  \n0  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.14  \n1  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.10  \n2  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.65  \n3  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.90  \n4  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      2.94  "
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4gKmDRi3YRo",
    "outputId": "9856621c-76fb-4165-c84c-4a0f59bc28b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "16000    10180\nName: sample_rate, dtype: int64"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "meta_df['sample_rate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPio4y_9RhvC",
    "outputId": "11664bc7-f4f9-4ca7-a8d8-e51082e08647"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['filename', 'transcription', 'filepath', 'sample_rate', 'duration']"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "meta_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gNHLp5mHSXbT",
    "outputId": "c5016151-e276-4a32-d608-e79168d2bc17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[array([['juma hili bara la afrika limeshuhudia raia wa nchi za niger']],\n       dtype=object),\n array([['na rais aliyetangulia henry konan berdi']], dtype=object),\n array([['baada ya kushinda katika uchaguzi mkuu wa taifa hilo']],\n       dtype=object),\n array([['siku ya jumatano maharamia hao wa kisomali']], dtype=object),\n array([['pamoja na abiria ishirini wakiwemo raia wa madagascar']],\n       dtype=object)]"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "txts = []\n",
    "for row in rows:\n",
    "    filename = row['filename']\n",
    "    filter = meta_df[meta_df['filename'] == filename]\n",
    "    txt = filter[['transcription']].values\n",
    "    txts.append(txt)\n",
    "\n",
    "txts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QtbOxUt-Vvzr"
   },
   "outputs": [],
   "source": [
    "txts = np.array(txts).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdRmO_PMWK7M",
    "outputId": "ac00c082-2c8a-427a-ec61-fc2127ecc6bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['juma hili bara la afrika limeshuhudia raia wa nchi za niger',\n       'na rais aliyetangulia henry konan berdi',\n       'baada ya kushinda katika uchaguzi mkuu wa taifa hilo',\n       'siku ya jumatano maharamia hao wa kisomali',\n       'pamoja na abiria ishirini wakiwemo raia wa madagascar'],\n      dtype=object)"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "txts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bj7dp_XDZFpb"
   },
   "outputs": [],
   "source": [
    "clean_txts = []\n",
    "alphabets = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'.split()\n",
    "for txt in txts:\n",
    "    clean_txt = []\n",
    "    for c in txt:\n",
    "        if c not in alphabets and c != ' ':\n",
    "            continue\n",
    "        clean_txt.append(c)\n",
    "    clean_txt = ''.join(clean_txt)\n",
    "    clean_txts.append(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hssO43laaId0",
    "outputId": "ff2a1320-85e4-4b6b-bad8-47a06097e194"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['juma hili bara la afrika limeshuhudia raia wa nchi za niger',\n 'na rais aliyetangulia henry konan berdi',\n 'baada ya kushinda katika uchaguzi mkuu wa taifa hilo',\n 'siku ya jumatano maharamia hao wa kisomali',\n 'pamoja na abiria ishirini wakiwemo raia wa madagascar']"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "clean_txts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "'' in clean_txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>texts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>na rais aliyetangulia henry konan berdi</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>baada ya kushinda katika uchaguzi mkuu wa taif...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>siku ya jumatano maharamia hao wa kisomali</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>pamoja na abiria ishirini wakiwemo raia wa mad...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                               texts\n0  juma hili bara la afrika limeshuhudia raia wa ...\n1            na rais aliyetangulia henry konan berdi\n2  baada ya kushinda katika uchaguzi mkuu wa taif...\n3         siku ya jumatano maharamia hao wa kisomali\n4  pamoja na abiria ishirini wakiwemo raia wa mad..."
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "df = pd.DataFrame(clean_txts)\n",
    "df.columns = ['texts']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Int64Index([51, 161, 190], dtype='int64')"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "idxs = df[df['texts'] == ''].index\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del clean_txts[idxs[-1]]\n",
    "del clean_txts[idxs[-2]]\n",
    "del clean_txts[idxs[-3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "'' in clean_txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sample_audios[idxs[-1]]\n",
    "del sample_audios[idxs[-2]]\n",
    "del sample_audios[idxs[-3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3Aa-Wdc7Rnq"
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30NG8Jgz1H56",
    "outputId": "686fe668-679b-4944-f761-902d9bcad9cf"
   },
   "outputs": [],
   "source": [
    "def character_dict():\n",
    "    alphabet = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'\n",
    "    supported = alphabet.split()\n",
    "\n",
    "    char_map = {}\n",
    "    char_map[\"\"] = 0\n",
    "    char_map[\"<SPACE>\"] = 1\n",
    "    idx = 2\n",
    "    for c in supported:\n",
    "        char_map[c] = idx\n",
    "        idx += 1\n",
    "    index_map = {v: k for k, v in char_map.items()}\n",
    "    return char_map, index_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_map, index_map = character_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'': 0,\n '<SPACE>': 1,\n 'a': 2,\n 'b': 3,\n 'c': 4,\n 'd': 5,\n 'e': 6,\n 'f': 7,\n 'g': 8,\n 'h': 9,\n 'i': 10,\n 'j': 11,\n 'k': 12,\n 'l': 13,\n 'm': 14,\n 'n': 15,\n 'o': 16,\n 'p': 17,\n 'q': 18,\n 'r': 19,\n 's': 20,\n 't': 21,\n 'u': 22,\n 'v': 23,\n 'w': 24,\n 'x': 25,\n 'y': 26,\n 'z': 27}"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "char_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9nJ78TV8X-b"
   },
   "outputs": [],
   "source": [
    "def text_to_int_sequence(text):\n",
    "    \"\"\" Convert text to an integer sequence \"\"\"\n",
    "    int_sequence = []\n",
    "    for c in text:\n",
    "        if c == ' ':\n",
    "            ch = char_map['<SPACE>']\n",
    "        elif c in alphabets:\n",
    "            ch = char_map[c]\n",
    "        else:\n",
    "            print(c)\n",
    "            print('character not found')\n",
    "            break\n",
    "        int_sequence.append(ch)\n",
    "    return np.array(int_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4y39Q5Bq6frJ"
   },
   "outputs": [],
   "source": [
    "def int_sequence_to_text(int_sequence):\n",
    "    \"\"\" Convert an integer sequence to text \"\"\"\n",
    "    textch = []\n",
    "    for c in int_sequence:\n",
    "        ch = index_map[c]\n",
    "        textch.append(ch)\n",
    "    text = ''.join(textch)\n",
    "    text = text.replace('<SPACE>', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmvz_Svx7U7l"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, audios, texts, batch_size=32):\n",
    "        self.audios = audios\n",
    "        self.texts = texts\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = int(len(self.audios) // self.batch_size)\n",
    "        # self.index = 0\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    # def shuffle(self):\n",
    "    #     np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(self.steps*self.batch_size)\n",
    "        # np.random.shuffle(self.indexes)\n",
    "\n",
    "    def data_generation(self, batch_audios, batch_texts):\n",
    "\n",
    "        longest_audio = max([len(i) for i in batch_audios])\n",
    "        longest_txt = max([len(i) for i in batch_texts])\n",
    "\n",
    "        audios          = np.zeros([int(self.batch_size), longest_audio], dtype=\"float32\")\n",
    "        txts            = np.zeros([int(self.batch_size), longest_txt], dtype=\"int64\")\n",
    "        audio_length    = np.zeros([int(self.batch_size)], dtype=\"int64\")\n",
    "        txt_length      = np.zeros([int(self.batch_size)], dtype=\"int64\")\n",
    "\n",
    "        i = 0\n",
    "        for audio, txt in zip(batch_audios, batch_texts):\n",
    "\n",
    "            txt_len = len(txt)\n",
    "\n",
    "            txt = text_to_int_sequence(txt)\n",
    "            # print(txts.shape)\n",
    "            # print(np.array(txt).shape)\n",
    "            txts[i,: txt_len] = txt\n",
    "\n",
    "            audio_len = len(audio)\n",
    "\n",
    "            audios[i, :audio_len] = audio\n",
    "\n",
    "            audio_length[i] = audio_len\n",
    "            txt_length[i] = txt_len\n",
    "\n",
    "            i+=1          \n",
    "            \n",
    "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "        inputs = {\n",
    "                    'the_input':    tf.convert_to_tensor(audios), \n",
    "                    'the_labels':   tf.convert_to_tensor(txts), \n",
    "                    'input_length': tf.convert_to_tensor(audio_length), \n",
    "                    'label_length': tf.convert_to_tensor(txt_length)\n",
    "                }\n",
    "        return (inputs, outputs)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[int(index*self.batch_size):int((index+1)*self.batch_size)]\n",
    "    \n",
    "        batch_audios = [self.audios[int(i)] for i in indexes]\n",
    "        batch_texts = [self.texts[int(i)] for i in indexes]\n",
    "        \n",
    "        return  self.data_generation(batch_audios, batch_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMZLj1GeQny1"
   },
   "outputs": [],
   "source": [
    "dg = DataGenerator(sample_audios, clean_txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9yv2uTEBcWp",
    "outputId": "46ab876c-41ec-4784-ea8b-03c9de62096a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "len(dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2V8FZlhWdIt"
   },
   "outputs": [],
   "source": [
    "batch1 = dg[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EvPWc-V09v-c",
    "outputId": "a9377aec-617b-4e23-a294-a0bbd0df73fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(32, 112), dtype=int64, numpy=\narray([[11, 22, 14, ...,  0,  0,  0],\n       [15,  2,  1, ...,  0,  0,  0],\n       [ 3,  2,  2, ...,  0,  0,  0],\n       ...,\n       [12, 10, 21, ...,  0,  0,  0],\n       [10, 13,  2, ..., 16, 27, 10],\n       [11,  6, 11, ...,  0,  0,  0]])>"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "batch1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogMelSpectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0lSFc5roaSe"
   },
   "outputs": [],
   "source": [
    "class LogMelSpectrogram(tf.keras.layers.Layer):\n",
    "    \"\"\"Compute log-magnitude mel-scaled spectrograms.\"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate, fft_size, hop_size, n_mels,\n",
    "                 f_min=0.0, f_max=None, **kwargs):\n",
    "        super(LogMelSpectrogram, self).__init__(**kwargs)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.fft_size = fft_size\n",
    "        self.hop_size = hop_size\n",
    "        self.n_mels = n_mels\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max if f_max else sample_rate / 2\n",
    "        self.mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
    "            num_mel_bins=self.n_mels,\n",
    "            num_spectrogram_bins=fft_size // 2 + 1,\n",
    "            sample_rate=self.sample_rate,\n",
    "            lower_edge_hertz=self.f_min,\n",
    "            upper_edge_hertz=self.f_max)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.non_trainable_weights.append(self.mel_filterbank)\n",
    "        super(LogMelSpectrogram, self).build(input_shape)\n",
    "\n",
    "    def call(self, waveforms):\n",
    "        \"\"\"Forward pass.\n",
    "        Parameters\n",
    "        ----------\n",
    "        waveforms : tf.Tensor, shape = (None, n_samples)\n",
    "            A Batch of mono waveforms.\n",
    "        Returns\n",
    "        -------\n",
    "        log_mel_spectrograms : (tf.Tensor), shape = (None, time, freq, ch)\n",
    "            The corresponding batch of log-mel-spectrograms\n",
    "        \"\"\"\n",
    "        def _tf_log10(x):\n",
    "            numerator = tf.math.log(x)\n",
    "            denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "            return numerator / denominator\n",
    "\n",
    "        def power_to_db(magnitude, amin=1e-16, top_db=80.0):\n",
    "            \"\"\"\n",
    "            https://librosa.github.io/librosa/generated/librosa.core.power_to_db.html\n",
    "            \"\"\"\n",
    "            ref_value = tf.reduce_max(magnitude)\n",
    "            log_spec = 10.0 * _tf_log10(tf.maximum(amin, magnitude))\n",
    "            log_spec -= 10.0 * _tf_log10(tf.maximum(amin, ref_value))\n",
    "            log_spec = tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n",
    "\n",
    "            return log_spec\n",
    "\n",
    "        spectrograms = tf.signal.stft(waveforms,\n",
    "                                      frame_length=self.fft_size,\n",
    "                                      frame_step=self.hop_size,\n",
    "                                      pad_end=False)\n",
    "\n",
    "        magnitude_spectrograms = tf.abs(spectrograms)\n",
    "\n",
    "        mel_spectrograms = tf.matmul(tf.square(magnitude_spectrograms),\n",
    "                                     self.mel_filterbank)\n",
    "\n",
    "        log_mel_spectrograms = power_to_db(mel_spectrograms)\n",
    "\n",
    "        # add channel dimension\n",
    "        log_mel_spectrograms = tf.expand_dims(log_mel_spectrograms, 3)\n",
    "\n",
    "        return log_mel_spectrograms\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'fft_size': self.fft_size,\n",
    "            'hop_size': self.hop_size,\n",
    "            'n_mels': self.n_mels,\n",
    "            'sample_rate': self.sample_rate,\n",
    "            'f_min': self.f_min,\n",
    "            'f_max': self.f_max,\n",
    "        }\n",
    "        config.update(super(LogMelSpectrogram, self).get_config())\n",
    "\n",
    "        return config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd0c30745a67ab3077685183c6616f760120387d2e186c7e6a99675e86d34cdfa12"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}