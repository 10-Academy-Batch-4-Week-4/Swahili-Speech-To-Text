{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Swahili_speech_recognition__.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jXSJhUykWNEp",
        "MktJECm-Wt6l",
        "JWpC5sdlXXS7",
        "TVNuBhwXXjyk",
        "vhrONKzmYGhY"
      ],
      "toc_visible": true,
      "mount_file_id": "17JXvg7cA4f5m9V2cCdOLFr85XTm6pRHJ",
      "authorship_tag": "ABX9TyPoYdx8/1e0fzbeeIwSEQEX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miz-ab/Swahili-Speech-To-Text/blob/main/notebooks/Swahili_speech_recognition__.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyUueqDqS7KU"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83EuwlSdTiS0",
        "outputId": "aa4d68d0-d458-4e70-adbd-dbf09eb7e6ac"
      },
      "source": [
        "rows = []\n",
        "p_dir = \"/content/drive/MyDrive/Week-4/speech_data/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/\"\n",
        "parent_dir = p_dir+\"SWH-05-20101106\"\n",
        "files = os.listdir(parent_dir)\n",
        "for f in files:\n",
        "    audio, fs = librosa.load(f\"{parent_dir}/{f}\")\n",
        "    filename = f.split('.')[0]\n",
        "    row = {'filename': filename, 'audio': audio}\n",
        "    rows.append(row)\n",
        "rows[:5]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'audio': array([0.02953335, 0.03225018, 0.02603412, ..., 0.09593043, 0.09478676,\n",
              "         0.05775513], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part10'},\n",
              " {'audio': array([ 0.00471402,  0.00630584,  0.00576152, ...,  0.01627303,\n",
              "         -0.00729037, -0.01463527], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part100'},\n",
              " {'audio': array([0.00886934, 0.00965257, 0.0063316 , ..., 0.22327209, 0.280469  ,\n",
              "         0.        ], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part101'},\n",
              " {'audio': array([-0.01096754, -0.01230842, -0.01015999, ..., -0.21667908,\n",
              "         -0.20379573, -0.11009098], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part102'},\n",
              " {'audio': array([0.01063866, 0.01384298, 0.01281647, ..., 0.0591335 , 0.05393954,\n",
              "         0.02577941], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part103'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1ULfMzGUcMC",
        "outputId": "b62a81dd-7ae8-402f-99ab-1bc35a43a39a"
      },
      "source": [
        "sample_audios = []\n",
        "for row in rows:\n",
        "    audio = row['audio']\n",
        "    sample_audios.append(audio)\n",
        "sample_audios[:5]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.02953335, 0.03225018, 0.02603412, ..., 0.09593043, 0.09478676,\n",
              "        0.05775513], dtype=float32),\n",
              " array([ 0.00471402,  0.00630584,  0.00576152, ...,  0.01627303,\n",
              "        -0.00729037, -0.01463527], dtype=float32),\n",
              " array([0.00886934, 0.00965257, 0.0063316 , ..., 0.22327209, 0.280469  ,\n",
              "        0.        ], dtype=float32),\n",
              " array([-0.01096754, -0.01230842, -0.01015999, ..., -0.21667908,\n",
              "        -0.20379573, -0.11009098], dtype=float32),\n",
              " array([0.01063866, 0.01384298, 0.01281647, ..., 0.0591335 , 0.05393954,\n",
              "        0.02577941], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MESf-LkUeon"
      },
      "source": [
        "meta_df = pd.read_csv('/content/drive/MyDrive/Swahili-Speech-To-Text-main___/metadata.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "Vujvz81gU6Gw",
        "outputId": "4d959666-a998-4235-9a23-6f381684f41c"
      },
      "source": [
        "meta_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>transcription</th>\n",
              "      <th>filepath</th>\n",
              "      <th>sample_rate</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            filename  ... duration\n",
              "0  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.14\n",
              "1  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.10\n",
              "2  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.65\n",
              "3  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.90\n",
              "4  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     2.94\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTLarZHwVGwK",
        "outputId": "aa06deef-d4a5-47a0-b461-06d2fa5d7606"
      },
      "source": [
        "meta_df['sample_rate'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16000    10180\n",
              "Name: sample_rate, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzmYiDpbVK49",
        "outputId": "c91894c3-7e89-4cd6-e818-ed74a54a8b65"
      },
      "source": [
        "meta_df.columns.to_list()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['filename', 'transcription', 'filepath', 'sample_rate', 'duration']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtZaEO_QVOZo",
        "outputId": "118b5408-c798-4cb9-c81f-5c0ea4f0c63c"
      },
      "source": [
        "txts = []\n",
        "for row in rows:\n",
        "    filename = row['filename']\n",
        "    filter = meta_df[meta_df['filename'] == filename]\n",
        "    txt = filter[['transcription']].values\n",
        "    txts.append(txt)\n",
        "\n",
        "txts[:5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([['rais wa tanzania jakaya mrisho kikwete']], dtype=object),\n",
              " array([['yanayo andaliwa nami pendo pondo idhaa ya kiswahili']],\n",
              "       dtype=object),\n",
              " array([['inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania']],\n",
              "       dtype=object),\n",
              " array([['juma hili bara la afrika limeshuhudia raia wa nchi za niger']],\n",
              "       dtype=object),\n",
              " array([['wakipiga kura ya maoni ilikufanya mabadiliko ya']], dtype=object)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGS-Ww2ZVSwM"
      },
      "source": [
        "txts = np.array(txts).reshape(-1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io-HYmvCVVQt",
        "outputId": "f7d2a916-0fda-47b8-d5b4-f425348630f3"
      },
      "source": [
        "txts[:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['rais wa tanzania jakaya mrisho kikwete',\n",
              "       'yanayo andaliwa nami pendo pondo idhaa ya kiswahili',\n",
              "       'inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania',\n",
              "       'juma hili bara la afrika limeshuhudia raia wa nchi za niger',\n",
              "       'wakipiga kura ya maoni ilikufanya mabadiliko ya'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx4Sz11OVZOf"
      },
      "source": [
        "clean_txts = []\n",
        "alphabets = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'.split()\n",
        "for txt in txts:\n",
        "    clean_txt = []\n",
        "    for c in txt:\n",
        "        if c not in alphabets and c != ' ':\n",
        "            continue\n",
        "        clean_txt.append(c)\n",
        "    clean_txt = ''.join(clean_txt)\n",
        "    clean_txts.append(clean_txt)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1fhpoJFVdRh",
        "outputId": "4210d3a2-1266-4840-b9b2-bf27b6067ed1"
      },
      "source": [
        "clean_txts[:5]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rais wa tanzania jakaya mrisho kikwete',\n",
              " 'yanayo andaliwa nami pendo pondo idhaa ya kiswahili',\n",
              " 'inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania',\n",
              " 'juma hili bara la afrika limeshuhudia raia wa nchi za niger',\n",
              " 'wakipiga kura ya maoni ilikufanya mabadiliko ya']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0IsalIWVgyJ",
        "outputId": "21194b64-8fe6-428b-be69-9cc4b8b76c26"
      },
      "source": [
        "'' in clean_txts"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5tGh2tlUVik6",
        "outputId": "f8452eac-91dc-495b-fa57-1a19cf9f98c3"
      },
      "source": [
        "df = pd.DataFrame(clean_txts)\n",
        "df.columns = ['texts']\n",
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts\n",
              "0             rais wa tanzania jakaya mrisho kikwete\n",
              "1  yanayo andaliwa nami pendo pondo idhaa ya kisw...\n",
              "2  inayokutangazia moja kwa moja kutoka jijini da...\n",
              "3  juma hili bara la afrika limeshuhudia raia wa ...\n",
              "4    wakipiga kura ya maoni ilikufanya mabadiliko ya"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp8sdTNLVoG1",
        "outputId": "e6da839d-bd8b-4628-f85f-7f98117ba3a0"
      },
      "source": [
        "idxs = df[df['texts'] == ''].index\n",
        "idxs"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([19, 21, 56], dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZrf5m7kVrt-"
      },
      "source": [
        "del clean_txts[idxs[-1]]\n",
        "del clean_txts[idxs[-2]]\n",
        "del clean_txts[idxs[-3]]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EqoZUPuVvGm",
        "outputId": "cd5bf0ce-6bce-4dab-fabc-33976a8d92f3"
      },
      "source": [
        "'' in clean_txts"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok8wX8WkWGhS"
      },
      "source": [
        "del sample_audios[idxs[-1]]\n",
        "del sample_audios[idxs[-2]]\n",
        "del sample_audios[idxs[-3]]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXSJhUykWNEp"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGZEVN9DWGmk"
      },
      "source": [
        "def character_dict():\n",
        "    alphabet = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'\n",
        "    supported = alphabet.split()\n",
        "\n",
        "    char_map = {}\n",
        "    char_map[\"\"] = 0\n",
        "    char_map[\"<SPACE>\"] = 1\n",
        "    idx = 2\n",
        "    for c in supported:\n",
        "        char_map[c] = idx\n",
        "        idx += 1\n",
        "    index_map = {v: k for k, v in char_map.items()}\n",
        "    return char_map, index_map"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "panYqn_vWX7s"
      },
      "source": [
        "char_map, index_map = character_dict()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJCgVN06WgV2",
        "outputId": "c7e3bbec-ada4-4127-ee40-8224a303ebdd"
      },
      "source": [
        "char_map"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " '<SPACE>': 1,\n",
              " 'a': 2,\n",
              " 'b': 3,\n",
              " 'c': 4,\n",
              " 'd': 5,\n",
              " 'e': 6,\n",
              " 'f': 7,\n",
              " 'g': 8,\n",
              " 'h': 9,\n",
              " 'i': 10,\n",
              " 'j': 11,\n",
              " 'k': 12,\n",
              " 'l': 13,\n",
              " 'm': 14,\n",
              " 'n': 15,\n",
              " 'o': 16,\n",
              " 'p': 17,\n",
              " 'q': 18,\n",
              " 'r': 19,\n",
              " 's': 20,\n",
              " 't': 21,\n",
              " 'u': 22,\n",
              " 'v': 23,\n",
              " 'w': 24,\n",
              " 'x': 25,\n",
              " 'y': 26,\n",
              " 'z': 27}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quNOFm8YWiGg"
      },
      "source": [
        "def text_to_int_sequence(text):\n",
        "    \"\"\" Convert text to an integer sequence \"\"\"\n",
        "    int_sequence = []\n",
        "    for c in text:\n",
        "        if c == ' ':\n",
        "            ch = char_map['<SPACE>']\n",
        "        elif c in alphabets:\n",
        "            ch = char_map[c]\n",
        "        else:\n",
        "            print(c)\n",
        "            print('character not found')\n",
        "            break\n",
        "        int_sequence.append(ch)\n",
        "    return np.array(int_sequence)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs65jLtUWnMZ"
      },
      "source": [
        "def int_sequence_to_text(int_sequence):\n",
        "    \"\"\" Convert an integer sequence to text \"\"\"\n",
        "    textch = []\n",
        "    for c in int_sequence:\n",
        "        ch = index_map[c]\n",
        "        textch.append(ch)\n",
        "    text = ''.join(textch)\n",
        "    text = text.replace('<SPACE>', ' ')\n",
        "    return text"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MktJECm-Wt6l"
      },
      "source": [
        "## Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em9xil43WyBi"
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, audios, texts, batch_size=32):\n",
        "        self.audios = audios\n",
        "        self.texts = texts\n",
        "        self.batch_size = batch_size\n",
        "        self.steps = int(len(self.audios) // self.batch_size)\n",
        "        # self.index = 0\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    # def shuffle(self):\n",
        "    #     np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.steps\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(self.steps*self.batch_size)\n",
        "        # np.random.shuffle(self.indexes)\n",
        "\n",
        "    def data_generation(self, batch_audios, batch_texts):\n",
        "\n",
        "        longest_audio = max([len(i) for i in batch_audios])\n",
        "        longest_txt = max([len(i) for i in batch_texts])\n",
        "\n",
        "        audios          = np.zeros([int(self.batch_size), longest_audio], dtype=\"float32\")\n",
        "        txts            = np.zeros([int(self.batch_size), longest_txt], dtype=\"int64\")\n",
        "        audio_length    = np.zeros([int(self.batch_size)], dtype=\"int64\")\n",
        "        txt_length      = np.zeros([int(self.batch_size)], dtype=\"int64\")\n",
        "\n",
        "        i = 0\n",
        "        for audio, txt in zip(batch_audios, batch_texts):\n",
        "\n",
        "            txt_len = len(txt)\n",
        "\n",
        "            txt = text_to_int_sequence(txt)\n",
        "            # print(txts.shape)\n",
        "            # print(np.array(txt).shape)\n",
        "            txts[i,: txt_len] = txt\n",
        "\n",
        "            audio_len = len(audio)\n",
        "\n",
        "            audios[i, :audio_len] = audio\n",
        "\n",
        "            audio_length[i] = audio_len\n",
        "            txt_length[i] = txt_len\n",
        "\n",
        "            i+=1          \n",
        "            \n",
        "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
        "        inputs = {\n",
        "                    'the_input':    tf.convert_to_tensor(audios), \n",
        "                    'the_labels':   tf.convert_to_tensor(txts), \n",
        "                    'input_length': tf.convert_to_tensor(audio_length), \n",
        "                    'label_length': tf.convert_to_tensor(txt_length)\n",
        "                }\n",
        "        return (inputs, outputs)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[int(index*self.batch_size):int((index+1)*self.batch_size)]\n",
        "    \n",
        "        batch_audios = [self.audios[int(i)] for i in indexes]\n",
        "        batch_texts = [self.texts[int(i)] for i in indexes]\n",
        "        \n",
        "        return  self.data_generation(batch_audios, batch_texts)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-Ezo721W5Y0"
      },
      "source": [
        "dg = DataGenerator(sample_audios, clean_txts)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29iYAZutXIt4",
        "outputId": "138795ac-f078-4723-c7bc-0fb555e8028b"
      },
      "source": [
        "len(dg)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bydWy7YCXLs3"
      },
      "source": [
        "batch1 = dg[0][0]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec6dhA8RXN-H",
        "outputId": "9a33a47a-5a14-4c43-ce43-b18ea0ee0354"
      },
      "source": [
        "batch1"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_length': <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
              " array([ 69237,  68355,  80483,  85995,  64827,  54023,  57771,  54684,\n",
              "         77837,  60417, 112455,  48069,  82688,  59094, 108266,  51597,\n",
              "         50054,  72545,  52700, 112455,  58653,  92831,  75411, 128993,\n",
              "         85995,  67694,  51818,  88202,  54023,  47628,  71883,  78057])>,\n",
              " 'label_length': <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
              " array([ 38,  51,  66,  59,  47,  30,  44,  36,  39,  38,  94,  38,  55,\n",
              "         35,  69,  34,  36,  42,  38,  61,  52,  59,  58, 102,  65,  52,\n",
              "         34,  55,  38,  25,  40,  60])>,\n",
              " 'the_input': <tf.Tensor: shape=(32, 128993), dtype=float32, numpy=\n",
              " array([[ 0.02953335,  0.03225018,  0.02603412, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.00471402,  0.00630584,  0.00576152, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.00886934,  0.00965257,  0.0063316 , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        ...,\n",
              "        [-0.01929947, -0.0214183 , -0.01492864, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.00464254,  0.00063416, -0.00608059, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [-0.02031364, -0.02287264, -0.02081008, ...,  0.        ,\n",
              "          0.        ,  0.        ]], dtype=float32)>,\n",
              " 'the_labels': <tf.Tensor: shape=(32, 102), dtype=int64, numpy=\n",
              " array([[19,  2, 10, ...,  0,  0,  0],\n",
              "        [26,  2, 15, ...,  0,  0,  0],\n",
              "        [10, 15,  2, ...,  0,  0,  0],\n",
              "        ...,\n",
              "        [12, 22, 13, ...,  0,  0,  0],\n",
              "        [15,  2,  1, ...,  0,  0,  0],\n",
              "        [22, 13, 10, ...,  0,  0,  0]])>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWpC5sdlXXS7"
      },
      "source": [
        "## LogMelSpectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0B7n_7ZXZXp"
      },
      "source": [
        "class LogMelSpectrogram(tf.keras.layers.Layer):\n",
        "    \"\"\"Compute log-magnitude mel-scaled spectrograms.\"\"\"\n",
        "\n",
        "    def __init__(self, sample_rate, fft_size, hop_size, n_mels,\n",
        "                 f_min=0.0, f_max=None, **kwargs):\n",
        "        super(LogMelSpectrogram, self).__init__(**kwargs)\n",
        "        self.sample_rate = sample_rate\n",
        "        self.fft_size = fft_size\n",
        "        self.hop_size = hop_size\n",
        "        self.n_mels = n_mels\n",
        "        self.f_min = f_min\n",
        "        self.f_max = f_max if f_max else sample_rate / 2\n",
        "        self.mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
        "            num_mel_bins=self.n_mels,\n",
        "            num_spectrogram_bins=fft_size // 2 + 1,\n",
        "            sample_rate=self.sample_rate,\n",
        "            lower_edge_hertz=self.f_min,\n",
        "            upper_edge_hertz=self.f_max)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.non_trainable_weights.append(self.mel_filterbank)\n",
        "        super(LogMelSpectrogram, self).build(input_shape)\n",
        "\n",
        "    def call(self, waveforms):\n",
        "        \"\"\"Forward pass.\n",
        "        Parameters\n",
        "        ----------\n",
        "        waveforms : tf.Tensor, shape = (None, n_samples)\n",
        "            A Batch of mono waveforms.\n",
        "        Returns\n",
        "        -------\n",
        "        log_mel_spectrograms : (tf.Tensor), shape = (None, time, freq, ch)\n",
        "            The corresponding batch of log-mel-spectrograms\n",
        "        \"\"\"\n",
        "        def _tf_log10(x):\n",
        "            numerator = tf.math.log(x)\n",
        "            denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
        "            return numerator / denominator\n",
        "\n",
        "        def power_to_db(magnitude, amin=1e-16, top_db=80.0):\n",
        "            \"\"\"\n",
        "            https://librosa.github.io/librosa/generated/librosa.core.power_to_db.html\n",
        "            \"\"\"\n",
        "            ref_value = tf.reduce_max(magnitude)\n",
        "            log_spec = 10.0 * _tf_log10(tf.maximum(amin, magnitude))\n",
        "            log_spec -= 10.0 * _tf_log10(tf.maximum(amin, ref_value))\n",
        "            log_spec = tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n",
        "\n",
        "            return log_spec\n",
        "\n",
        "        spectrograms = tf.signal.stft(waveforms,\n",
        "                                      frame_length=self.fft_size,\n",
        "                                      frame_step=self.hop_size,\n",
        "                                      pad_end=False)\n",
        "\n",
        "        magnitude_spectrograms = tf.abs(spectrograms)\n",
        "\n",
        "        mel_spectrograms = tf.matmul(tf.square(magnitude_spectrograms),\n",
        "                                     self.mel_filterbank)\n",
        "\n",
        "        log_mel_spectrograms = power_to_db(mel_spectrograms)\n",
        "\n",
        "        # add channel dimension\n",
        "        log_mel_spectrograms = tf.expand_dims(log_mel_spectrograms, 3)\n",
        "\n",
        "        return log_mel_spectrograms\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'fft_size': self.fft_size,\n",
        "            'hop_size': self.hop_size,\n",
        "            'n_mels': self.n_mels,\n",
        "            'sample_rate': self.sample_rate,\n",
        "            'f_min': self.f_min,\n",
        "            'f_max': self.f_max,\n",
        "        }\n",
        "        config.update(super(LogMelSpectrogram, self).get_config())\n",
        "\n",
        "        return config"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVNuBhwXXjyk"
      },
      "source": [
        "## CTC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNm-rzCqX3go"
      },
      "source": [
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2MxhB4SX8U8"
      },
      "source": [
        "def input_lengths_lambda_func(args):\n",
        "    input_length = args\n",
        "    return tf.cast(tf.math.floor(input_length/hop_size)-1, dtype=\"float32\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jzYXyV3YB_B"
      },
      "source": [
        "def add_ctc_loss(model_builder):\n",
        "    the_labels      = Input(name='the_labels',      shape=(None,), dtype='float32')\n",
        "    input_lengths   = Input(name='input_length',    shape=(1,), dtype='float32')\n",
        "    label_lengths   = Input(name='label_length',    shape=(1,), dtype='float32')\n",
        "\n",
        "    input_lengths2 = Lambda(input_lengths_lambda_func)(input_lengths)\n",
        "    if model_builder.output_length:\n",
        "         output_lengths  = Lambda(model_builder.output_length)(input_lengths2)\n",
        "    else:\n",
        "         output_lengths  = input_lengths2\n",
        "    \n",
        "    # CTC loss is implemented in a lambda layer\n",
        "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([model_builder.output, the_labels, output_lengths, label_lengths])\n",
        "    model = Model( inputs=[model_builder.input, the_labels, input_lengths, label_lengths],  outputs=loss_out)\n",
        "    return model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhrONKzmYGhY"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKxnAGWeYr7l"
      },
      "source": [
        "def preprocessin_model(sample_rate, fft_size, frame_step, n_mels, mfcc=False):\n",
        "\n",
        "    input_data = Input(name='input', shape=(None,), dtype=\"float32\")\n",
        "    featLayer = LogMelSpectrogram(\n",
        "        fft_size=fft_size,\n",
        "        hop_size=frame_step,\n",
        "        n_mels=n_mels,\n",
        "        \n",
        "        sample_rate=sample_rate,\n",
        "        f_min=0.0,\n",
        "        \n",
        "        f_max=int(sample_rate / 2)\n",
        "    )(input_data)\n",
        "    \n",
        "    x = BatchNormalization()(featLayer)\n",
        "    model = Model(inputs=input_data, outputs=x, name=\"preprocessin_model\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaSgydvfYwnd"
      },
      "source": [
        "def simple_rnn_model(input_dim, output_dim=224):\n",
        "\n",
        "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
        "    simp_rnn = GRU(output_dim, return_sequences=True,\n",
        "                   implementation=2, name='rnn')(input_data)\n",
        "    y_pred = Activation('softmax', name='softmax')(simp_rnn)\n",
        "    model = Model(inputs=input_data, outputs=y_pred, name=\"simple_rnn_model\")\n",
        "    model.output_length = lambda x: x\n",
        "    return model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM2PQVaSY0z1"
      },
      "source": [
        "def train(model_builder, \n",
        "          data_gen,\n",
        "          epochs, \n",
        "          verbose=1,\n",
        "          optimizer=SGD(learning_rate=0.002, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\n",
        "          ):    \n",
        "              \n",
        "    model = add_ctc_loss(model_builder)\n",
        "\n",
        "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
        "    print(model.summary())\n",
        "\n",
        "\n",
        "    hist = model.fit_generator(generator=data_gen,\n",
        "                               epochs=epochs,\n",
        "                               verbose=verbose, \n",
        "                               use_multiprocessing=False)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gguldrk_ciyx"
      },
      "source": [
        "## Model Trainig"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OOQUWGwcl2U"
      },
      "source": [
        "sample_rate = 16000\n",
        "fft_size = 1024\n",
        "frame_step = 512\n",
        "n_mels = 128\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 1\n",
        "data_len = len(clean_txts)\n",
        "output_dim = len(char_map) + 2\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGvtmfgucrvU"
      },
      "source": [
        "dg = DataGenerator(sample_audios, clean_txts, batch_size)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvUVD-Y9ctlP",
        "outputId": "60b533a4-5cc9-417b-844e-a0fd2668187f"
      },
      "source": [
        "preprocess_model = preprocessin_model(sample_rate, fft_size, frame_step, n_mels)\n",
        "preprocess_model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"preprocessin_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "log_mel_spectrogram (LogMelS (None, None, 128, 1)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, None, 128, 1)      4         \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 2\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FyQLOaJcxN-",
        "outputId": "8ee6c92c-d669-41a6-dfba-09e069b1288b"
      },
      "source": [
        "speech_model = simple_rnn_model(n_mels, output_dim)\n",
        "speech_model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"simple_rnn_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "the_input (InputLayer)       [(None, None, 128)]       0         \n",
            "_________________________________________________________________\n",
            "rnn (GRU)                    (None, None, 30)          14400     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, None, 30)          0         \n",
            "=================================================================\n",
            "Total params: 14,400\n",
            "Trainable params: 14,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raZU4Q6Cc4r-"
      },
      "source": [
        "def build_model(output_dim, custom_model, preprocess_model, mfcc=False, calc=None):\n",
        "\n",
        "    input_audios = Input(name='the_input', shape=(None,))\n",
        "    pre = preprocess_model(input_audios)\n",
        "    pre = tf.squeeze(pre, [3])\n",
        "\n",
        "    y_pred = custom_model(pre)\n",
        "    model = Model(inputs=input_audios, outputs=y_pred, name=\"model_builder\")\n",
        "    model.output_length = calc\n",
        "\n",
        "    return model"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w_JzuhUc6Gl",
        "outputId": "a7b1d4e1-a7a4-4fd4-cb58-ef797f2b240f"
      },
      "source": [
        "model = build_model(output_dim, speech_model, preprocess_model)\n",
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_builder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "the_input (InputLayer)       [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "preprocessin_model (Function (None, None, 128, 1)      4         \n",
            "_________________________________________________________________\n",
            "tf.compat.v1.squeeze (TFOpLa (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_model (Functional (None, None, 30)          14400     \n",
            "=================================================================\n",
            "Total params: 14,404\n",
            "Trainable params: 14,402\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gI7Pq3bdCtM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0fcd8adc-5246-4a97-ae56-f8e02453a5d2"
      },
      "source": [
        "!pip install mlflow\n",
        "import mlflow\n",
        "import mlflow.tensorflow"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-1.19.0-py3-none-any.whl (14.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.4 MB 59 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2.23.0)\n",
            "Collecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting docker>=4.0.0\n",
            "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.19.5)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (7.1.2)\n",
            "Collecting alembic<=1.4.1\n",
            "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 57.9 MB/s \n",
            "\u001b[?25hCollecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.15.0.tar.gz (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.3)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow) (21.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow) (2018.9)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.0)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.4)\n",
            "Collecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 61.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.20)\n",
            "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.17.3)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic<=1.4.1->mlflow) (2.8.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.2.0-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 963 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow) (4.6.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow) (2.0.1)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn->mlflow) (57.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->mlflow) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mlflow) (2.4.7)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow) (0.11.0)\n",
            "Building wheels for collected packages: alembic, databricks-cli, prometheus-flask-exporter\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158170 sha256=4355b519c1b7059279916f1cb61d5720a57f9eb1d9dd6e6a83c7898de6b27ec2\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.15.0-py3-none-any.whl size=105259 sha256=a09bf076ff3c2d7efb25232d7cc659f16f4388c4bcfcebb2ee42326a75a9bac4\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/ba/75/284f9a90ff7a010bb23b9798f2e9a19dd9fe619379c917bff4\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17416 sha256=aab688f86b223f251bc1a47bf07cfa60b8e9168183082367bc4678bf9ef8d361\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/1e/1c/c765920cb92b2f0343d2dd8b481a407cee2823f9b4bbd2e52a\n",
            "Successfully built alembic databricks-cli prometheus-flask-exporter\n",
            "Installing collected packages: smmap, websocket-client, python-editor, Mako, gitdb, querystring-parser, pyyaml, prometheus-flask-exporter, gunicorn, gitpython, docker, databricks-cli, alembic, mlflow\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed Mako-1.1.4 alembic-1.4.1 databricks-cli-0.15.0 docker-5.0.0 gitdb-4.0.7 gitpython-3.1.18 gunicorn-20.1.0 mlflow-1.19.0 prometheus-flask-exporter-0.18.2 python-editor-1.0.4 pyyaml-5.4.1 querystring-parser-1.2.4 smmap-4.0.0 websocket-client-1.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L_v7Y1zeDMy"
      },
      "source": [
        "\n",
        "#mlflow.set_experiment('Speech model simple rnn')\n",
        "mlflow.tensorflow.autolog()\n",
        "hop_size = 512\n",
        "train(model, dg, epochs=10)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjgM33P_tOf-"
      },
      "source": [
        "!pip install mlflow --quiet\n",
        "#get_ipython().system_raw(\"mlflow ui --port 5000 &\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmOu3R97uuPu"
      },
      "source": [
        "import mlflow\n",
        "import mlflow.tensorflow"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWx6YOZ6u7D5",
        "outputId": "4ce910fc-7c03-4927-e454-c9d381030d74"
      },
      "source": [
        "print(mlflow.__version__)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.19.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpeL5tKcxBvC",
        "outputId": "22b5581b-e8bd-459b-d848-8d826a28d025"
      },
      "source": [
        "#mlflow.set_experiment('Speech model simple rnn')\n",
        "mlflow.tensorflow.autolog()\n",
        "hop_size = 512\n",
        "train(model, dg, epochs=10)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "2021/08/12 14:46:30 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.7/dist-packages/mlflow/utils/autologging_utils/safety.py:216: UserWarning: Logging to MLflow failed: dump_all() got an unexpected keyword argument 'sort_keys'\"\n",
            "2021/08/12 14:46:31 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: 'NoneType' object does not support item assignment\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input (InputLayer)          [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "preprocessin_model (Functional) (None, None, 128, 1) 4           the_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.squeeze (TFOpLambd (None, None, 128)    0           preprocessin_model[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "input_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "simple_rnn_model (Functional)   (None, None, 30)     14400       tf.compat.v1.squeeze[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "the_labels (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 1)            0           input_length[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "label_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc (Lambda)                    (None, 1)            0           simple_rnn_model[0][0]           \n",
            "                                                                 the_labels[0][0]                 \n",
            "                                                                 lambda[0][0]                     \n",
            "                                                                 label_length[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 14,404\n",
            "Trainable params: 14,402\n",
            "Non-trainable params: 2\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 10s 1s/step - loss: 383.5024\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 314.1604\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 271.9309\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 243.1213\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 237.1913\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 235.7113\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 234.9878\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 234.7774\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 234.6135\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 234.2303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhAlA0zmyKrD"
      },
      "source": [
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\")\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2yeMeR4yOZ9",
        "outputId": "d4d2be91-ea15-404c-9fa8-bb82936a3b6e"
      },
      "source": [
        "# create remote tunnel using ngrok.com to allow local port access\n",
        "# borrowed from https://colab.research.google.com/github/alfozan/MLflow-GBRT-demo/blob/master/MLflow-GBRT-demo.ipynb#scrollTo=4h3bKHMYUIG6\n",
        "!pip install pyngrok --quiet\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"1wapFvhRg5H9n37F6O6lPlJkQR4_7284vGstG3Z6uBEpkYCZJ\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "public_url = ngrok.connect(port=\"5000\", proto=\"http\", options={\"bind_tls\": True})\n",
        "print(\"MLflow Tracking UI:\", public_url)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 440 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 450 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 460 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 471 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 481 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 491 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 501 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 512 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 522 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 532 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 542 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 552 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 563 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 573 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 583 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 593 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 604 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 614 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 624 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 634 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 645 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 655 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 665 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 675 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 686 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 696 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 706 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 716 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 727 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 737 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 746 kB 5.1 MB/s \n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "MLflow Tracking UI: NgrokTunnel: \"http://87c560c8dc82.ngrok.io\" -> \"http://localhost:80\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIzEIUDsZ82t"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUw8B8H2aJ65"
      },
      "source": [
        "!pip install pyngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6-lswKQaZie"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "# To make things easier later, we're also importing numpy and pandas for\n",
        "# working with sample data.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "st.title('My first app')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0kXB-QwbtCg"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_IHoav0b5df"
      },
      "source": [
        "!ngrok authtoken 1wapFvhRg5H9n37F6O6lPlJkQR4_7284vGstG3Z6uBEpkYCZJ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoTySQNQckdW"
      },
      "source": [
        "from pyngrok import ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNDyZva2dc6a"
      },
      "source": [
        "!pgrep streamlit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eBiqfzidCJ_"
      },
      "source": [
        "!streamlit run app.py&>/dev/null&"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgDFSjwGcyu-"
      },
      "source": [
        "public_url = ngrok.connect(port=\"8080\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZrU89cZd0VY"
      },
      "source": [
        "public_url"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}