{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Swahili_speech_recognition__.ipynb",
      "provenance": [],
      "mount_file_id": "17JXvg7cA4f5m9V2cCdOLFr85XTm6pRHJ",
      "authorship_tag": "ABX9TyN38seTcnFdtcDXlG54/XH8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miz-ab/Swahili-Speech-To-Text/blob/main/notebooks/Swahili_speech_recognition__.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyUueqDqS7KU"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83EuwlSdTiS0",
        "outputId": "77059c37-8b83-4bf4-925d-665fbcc58b91"
      },
      "source": [
        "rows = []\n",
        "p_dir = \"/content/drive/MyDrive/Week-4/speech_data/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/\"\n",
        "parent_dir = p_dir+\"SWH-05-20101106\"\n",
        "files = os.listdir(parent_dir)\n",
        "for f in files:\n",
        "    audio, fs = librosa.load(f\"{parent_dir}/{f}\")\n",
        "    filename = f.split('.')[0]\n",
        "    row = {'filename': filename, 'audio': audio}\n",
        "    rows.append(row)\n",
        "rows[:5]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'audio': array([0.02953335, 0.03225018, 0.02603412, ..., 0.09593043, 0.09478676,\n",
              "         0.05775513], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part10'},\n",
              " {'audio': array([ 0.00471402,  0.00630584,  0.00576152, ...,  0.01627303,\n",
              "         -0.00729037, -0.01463527], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part100'},\n",
              " {'audio': array([0.00886934, 0.00965257, 0.0063316 , ..., 0.22327209, 0.280469  ,\n",
              "         0.        ], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part101'},\n",
              " {'audio': array([-0.01096754, -0.01230842, -0.01015999, ..., -0.21667908,\n",
              "         -0.20379573, -0.11009098], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part102'},\n",
              " {'audio': array([0.01063866, 0.01384298, 0.01281647, ..., 0.0591335 , 0.05393954,\n",
              "         0.02577941], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part103'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1ULfMzGUcMC",
        "outputId": "61bd5798-380c-4d5a-c8b5-56c7dc1eb50a"
      },
      "source": [
        "sample_audios = []\n",
        "for row in rows:\n",
        "    audio = row['audio']\n",
        "    sample_audios.append(audio)\n",
        "sample_audios[:5]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.02953335, 0.03225018, 0.02603412, ..., 0.09593043, 0.09478676,\n",
              "        0.05775513], dtype=float32),\n",
              " array([ 0.00471402,  0.00630584,  0.00576152, ...,  0.01627303,\n",
              "        -0.00729037, -0.01463527], dtype=float32),\n",
              " array([0.00886934, 0.00965257, 0.0063316 , ..., 0.22327209, 0.280469  ,\n",
              "        0.        ], dtype=float32),\n",
              " array([-0.01096754, -0.01230842, -0.01015999, ..., -0.21667908,\n",
              "        -0.20379573, -0.11009098], dtype=float32),\n",
              " array([0.01063866, 0.01384298, 0.01281647, ..., 0.0591335 , 0.05393954,\n",
              "        0.02577941], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MESf-LkUeon"
      },
      "source": [
        "meta_df = pd.read_csv('/content/drive/MyDrive/Swahili-Speech-To-Text-main___/metadata.csv')"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "Vujvz81gU6Gw",
        "outputId": "914de88d-95cb-4527-d6c3-1173b5df5618"
      },
      "source": [
        "meta_df.head()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>transcription</th>\n",
              "      <th>filepath</th>\n",
              "      <th>sample_rate</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            filename  ... duration\n",
              "0  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.14\n",
              "1  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.10\n",
              "2  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.65\n",
              "3  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.90\n",
              "4  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     2.94\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTLarZHwVGwK",
        "outputId": "283bb2b6-1327-4a29-b400-c0768dcbd57d"
      },
      "source": [
        "meta_df['sample_rate'].value_counts()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16000    10180\n",
              "Name: sample_rate, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzmYiDpbVK49",
        "outputId": "50bf6f34-bee1-48cf-dd03-0ac735253d6a"
      },
      "source": [
        "meta_df.columns.to_list()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['filename', 'transcription', 'filepath', 'sample_rate', 'duration']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtZaEO_QVOZo",
        "outputId": "f0fc6a09-efd7-4ec5-cd42-d0fc83223c03"
      },
      "source": [
        "txts = []\n",
        "for row in rows:\n",
        "    filename = row['filename']\n",
        "    filter = meta_df[meta_df['filename'] == filename]\n",
        "    txt = filter[['transcription']].values\n",
        "    txts.append(txt)\n",
        "\n",
        "txts[:5]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([['rais wa tanzania jakaya mrisho kikwete']], dtype=object),\n",
              " array([['yanayo andaliwa nami pendo pondo idhaa ya kiswahili']],\n",
              "       dtype=object),\n",
              " array([['inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania']],\n",
              "       dtype=object),\n",
              " array([['juma hili bara la afrika limeshuhudia raia wa nchi za niger']],\n",
              "       dtype=object),\n",
              " array([['wakipiga kura ya maoni ilikufanya mabadiliko ya']], dtype=object)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGS-Ww2ZVSwM"
      },
      "source": [
        "txts = np.array(txts).reshape(-1)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io-HYmvCVVQt",
        "outputId": "01e7fb7a-47e6-41b5-cab0-f461d237f4fc"
      },
      "source": [
        "txts[:5]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['rais wa tanzania jakaya mrisho kikwete',\n",
              "       'yanayo andaliwa nami pendo pondo idhaa ya kiswahili',\n",
              "       'inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania',\n",
              "       'juma hili bara la afrika limeshuhudia raia wa nchi za niger',\n",
              "       'wakipiga kura ya maoni ilikufanya mabadiliko ya'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx4Sz11OVZOf"
      },
      "source": [
        "clean_txts = []\n",
        "alphabets = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'.split()\n",
        "for txt in txts:\n",
        "    clean_txt = []\n",
        "    for c in txt:\n",
        "        if c not in alphabets and c != ' ':\n",
        "            continue\n",
        "        clean_txt.append(c)\n",
        "    clean_txt = ''.join(clean_txt)\n",
        "    clean_txts.append(clean_txt)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1fhpoJFVdRh",
        "outputId": "0f1b9116-1bee-47b0-fb05-17de14482bca"
      },
      "source": [
        "clean_txts[:5]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rais wa tanzania jakaya mrisho kikwete',\n",
              " 'yanayo andaliwa nami pendo pondo idhaa ya kiswahili',\n",
              " 'inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania',\n",
              " 'juma hili bara la afrika limeshuhudia raia wa nchi za niger',\n",
              " 'wakipiga kura ya maoni ilikufanya mabadiliko ya']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0IsalIWVgyJ",
        "outputId": "ec67f1d4-b906-4b9e-f5bf-2a0a024c18dc"
      },
      "source": [
        "'' in clean_txts"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5tGh2tlUVik6",
        "outputId": "325f22e5-b59c-4f94-f1f9-63a46e9aad0b"
      },
      "source": [
        "df = pd.DataFrame(clean_txts)\n",
        "df.columns = ['texts']\n",
        "df.head()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts\n",
              "0             rais wa tanzania jakaya mrisho kikwete\n",
              "1  yanayo andaliwa nami pendo pondo idhaa ya kisw...\n",
              "2  inayokutangazia moja kwa moja kutoka jijini da...\n",
              "3  juma hili bara la afrika limeshuhudia raia wa ...\n",
              "4    wakipiga kura ya maoni ilikufanya mabadiliko ya"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp8sdTNLVoG1",
        "outputId": "22939fff-5672-4c65-f019-9926c894ab13"
      },
      "source": [
        "idxs = df[df['texts'] == ''].index\n",
        "idxs"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([19, 21, 56], dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZrf5m7kVrt-"
      },
      "source": [
        "del clean_txts[idxs[-1]]\n",
        "del clean_txts[idxs[-2]]\n",
        "del clean_txts[idxs[-3]]"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EqoZUPuVvGm",
        "outputId": "17091694-acea-4c3d-c526-582ce04c0a38"
      },
      "source": [
        "'' in clean_txts"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok8wX8WkWGhS"
      },
      "source": [
        "del sample_audios[idxs[-1]]\n",
        "del sample_audios[idxs[-2]]\n",
        "del sample_audios[idxs[-3]]"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXSJhUykWNEp"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGZEVN9DWGmk"
      },
      "source": [
        "def character_dict():\n",
        "    alphabet = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'\n",
        "    supported = alphabet.split()\n",
        "\n",
        "    char_map = {}\n",
        "    char_map[\"\"] = 0\n",
        "    char_map[\"<SPACE>\"] = 1\n",
        "    idx = 2\n",
        "    for c in supported:\n",
        "        char_map[c] = idx\n",
        "        idx += 1\n",
        "    index_map = {v: k for k, v in char_map.items()}\n",
        "    return char_map, index_map"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "panYqn_vWX7s"
      },
      "source": [
        "char_map, index_map = character_dict()"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJCgVN06WgV2",
        "outputId": "d80b0140-d021-45c6-f025-c099d6cc8639"
      },
      "source": [
        "char_map"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " '<SPACE>': 1,\n",
              " 'a': 2,\n",
              " 'b': 3,\n",
              " 'c': 4,\n",
              " 'd': 5,\n",
              " 'e': 6,\n",
              " 'f': 7,\n",
              " 'g': 8,\n",
              " 'h': 9,\n",
              " 'i': 10,\n",
              " 'j': 11,\n",
              " 'k': 12,\n",
              " 'l': 13,\n",
              " 'm': 14,\n",
              " 'n': 15,\n",
              " 'o': 16,\n",
              " 'p': 17,\n",
              " 'q': 18,\n",
              " 'r': 19,\n",
              " 's': 20,\n",
              " 't': 21,\n",
              " 'u': 22,\n",
              " 'v': 23,\n",
              " 'w': 24,\n",
              " 'x': 25,\n",
              " 'y': 26,\n",
              " 'z': 27}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quNOFm8YWiGg"
      },
      "source": [
        "def text_to_int_sequence(text):\n",
        "    \"\"\" Convert text to an integer sequence \"\"\"\n",
        "    int_sequence = []\n",
        "    for c in text:\n",
        "        if c == ' ':\n",
        "            ch = char_map['<SPACE>']\n",
        "        elif c in alphabets:\n",
        "            ch = char_map[c]\n",
        "        else:\n",
        "            print(c)\n",
        "            print('character not found')\n",
        "            break\n",
        "        int_sequence.append(ch)\n",
        "    return np.array(int_sequence)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs65jLtUWnMZ"
      },
      "source": [
        "def int_sequence_to_text(int_sequence):\n",
        "    \"\"\" Convert an integer sequence to text \"\"\"\n",
        "    textch = []\n",
        "    for c in int_sequence:\n",
        "        ch = index_map[c]\n",
        "        textch.append(ch)\n",
        "    text = ''.join(textch)\n",
        "    text = text.replace('<SPACE>', ' ')\n",
        "    return text"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MktJECm-Wt6l"
      },
      "source": [
        "## Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em9xil43WyBi"
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, audios, texts, batch_size=32):\n",
        "        self.audios = audios\n",
        "        self.texts = texts\n",
        "        self.batch_size = batch_size\n",
        "        self.steps = int(len(self.audios) // self.batch_size)\n",
        "        # self.index = 0\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    # def shuffle(self):\n",
        "    #     np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.steps\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(self.steps*self.batch_size)\n",
        "        # np.random.shuffle(self.indexes)\n",
        "\n",
        "    def data_generation(self, batch_audios, batch_texts):\n",
        "\n",
        "        longest_audio = max([len(i) for i in batch_audios])\n",
        "        longest_txt = max([len(i) for i in batch_texts])\n",
        "\n",
        "        audios          = np.zeros([int(self.batch_size), longest_audio], dtype=\"float32\")\n",
        "        txts            = np.zeros([int(self.batch_size), longest_txt], dtype=\"int64\")\n",
        "        audio_length    = np.zeros([int(self.batch_size)], dtype=\"int64\")\n",
        "        txt_length      = np.zeros([int(self.batch_size)], dtype=\"int64\")\n",
        "\n",
        "        i = 0\n",
        "        for audio, txt in zip(batch_audios, batch_texts):\n",
        "\n",
        "            txt_len = len(txt)\n",
        "\n",
        "            txt = text_to_int_sequence(txt)\n",
        "            # print(txts.shape)\n",
        "            # print(np.array(txt).shape)\n",
        "            txts[i,: txt_len] = txt\n",
        "\n",
        "            audio_len = len(audio)\n",
        "\n",
        "            audios[i, :audio_len] = audio\n",
        "\n",
        "            audio_length[i] = audio_len\n",
        "            txt_length[i] = txt_len\n",
        "\n",
        "            i+=1          \n",
        "            \n",
        "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
        "        inputs = {\n",
        "                    'the_input':    tf.convert_to_tensor(audios), \n",
        "                    'the_labels':   tf.convert_to_tensor(txts), \n",
        "                    'input_length': tf.convert_to_tensor(audio_length), \n",
        "                    'label_length': tf.convert_to_tensor(txt_length)\n",
        "                }\n",
        "        return (inputs, outputs)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[int(index*self.batch_size):int((index+1)*self.batch_size)]\n",
        "    \n",
        "        batch_audios = [self.audios[int(i)] for i in indexes]\n",
        "        batch_texts = [self.texts[int(i)] for i in indexes]\n",
        "        \n",
        "        return  self.data_generation(batch_audios, batch_texts)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-Ezo721W5Y0"
      },
      "source": [
        "dg = DataGenerator(sample_audios, clean_txts)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29iYAZutXIt4",
        "outputId": "829b2777-3fd7-46a3-bbb9-2594e62c1c2a"
      },
      "source": [
        "len(dg)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bydWy7YCXLs3"
      },
      "source": [
        "batch1 = dg[0][0]"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec6dhA8RXN-H",
        "outputId": "d0cfba48-6457-4a68-dfe5-3860cd97cfb7"
      },
      "source": [
        "batch1"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_length': <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
              " array([ 69237,  68355,  80483,  85995,  64827,  54023,  57771,  54684,\n",
              "         77837,  60417, 112455,  48069,  82688,  59094, 108266,  51597,\n",
              "         50054,  72545,  52700, 112455,  58653,  92831,  75411, 128993,\n",
              "         85995,  67694,  51818,  88202,  54023,  47628,  71883,  78057])>,\n",
              " 'label_length': <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
              " array([ 38,  51,  66,  59,  47,  30,  44,  36,  39,  38,  94,  38,  55,\n",
              "         35,  69,  34,  36,  42,  38,  61,  52,  59,  58, 102,  65,  52,\n",
              "         34,  55,  38,  25,  40,  60])>,\n",
              " 'the_input': <tf.Tensor: shape=(32, 128993), dtype=float32, numpy=\n",
              " array([[ 0.02953335,  0.03225018,  0.02603412, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.00471402,  0.00630584,  0.00576152, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.00886934,  0.00965257,  0.0063316 , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        ...,\n",
              "        [-0.01929947, -0.0214183 , -0.01492864, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.00464254,  0.00063416, -0.00608059, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [-0.02031364, -0.02287264, -0.02081008, ...,  0.        ,\n",
              "          0.        ,  0.        ]], dtype=float32)>,\n",
              " 'the_labels': <tf.Tensor: shape=(32, 102), dtype=int64, numpy=\n",
              " array([[19,  2, 10, ...,  0,  0,  0],\n",
              "        [26,  2, 15, ...,  0,  0,  0],\n",
              "        [10, 15,  2, ...,  0,  0,  0],\n",
              "        ...,\n",
              "        [12, 22, 13, ...,  0,  0,  0],\n",
              "        [15,  2,  1, ...,  0,  0,  0],\n",
              "        [22, 13, 10, ...,  0,  0,  0]])>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWpC5sdlXXS7"
      },
      "source": [
        "## LogMelSpectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0B7n_7ZXZXp"
      },
      "source": [
        "class LogMelSpectrogram(tf.keras.layers.Layer):\n",
        "    \"\"\"Compute log-magnitude mel-scaled spectrograms.\"\"\"\n",
        "\n",
        "    def __init__(self, sample_rate, fft_size, hop_size, n_mels,\n",
        "                 f_min=0.0, f_max=None, **kwargs):\n",
        "        super(LogMelSpectrogram, self).__init__(**kwargs)\n",
        "        self.sample_rate = sample_rate\n",
        "        self.fft_size = fft_size\n",
        "        self.hop_size = hop_size\n",
        "        self.n_mels = n_mels\n",
        "        self.f_min = f_min\n",
        "        self.f_max = f_max if f_max else sample_rate / 2\n",
        "        self.mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
        "            num_mel_bins=self.n_mels,\n",
        "            num_spectrogram_bins=fft_size // 2 + 1,\n",
        "            sample_rate=self.sample_rate,\n",
        "            lower_edge_hertz=self.f_min,\n",
        "            upper_edge_hertz=self.f_max)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.non_trainable_weights.append(self.mel_filterbank)\n",
        "        super(LogMelSpectrogram, self).build(input_shape)\n",
        "\n",
        "    def call(self, waveforms):\n",
        "        \"\"\"Forward pass.\n",
        "        Parameters\n",
        "        ----------\n",
        "        waveforms : tf.Tensor, shape = (None, n_samples)\n",
        "            A Batch of mono waveforms.\n",
        "        Returns\n",
        "        -------\n",
        "        log_mel_spectrograms : (tf.Tensor), shape = (None, time, freq, ch)\n",
        "            The corresponding batch of log-mel-spectrograms\n",
        "        \"\"\"\n",
        "        def _tf_log10(x):\n",
        "            numerator = tf.math.log(x)\n",
        "            denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
        "            return numerator / denominator\n",
        "\n",
        "        def power_to_db(magnitude, amin=1e-16, top_db=80.0):\n",
        "            \"\"\"\n",
        "            https://librosa.github.io/librosa/generated/librosa.core.power_to_db.html\n",
        "            \"\"\"\n",
        "            ref_value = tf.reduce_max(magnitude)\n",
        "            log_spec = 10.0 * _tf_log10(tf.maximum(amin, magnitude))\n",
        "            log_spec -= 10.0 * _tf_log10(tf.maximum(amin, ref_value))\n",
        "            log_spec = tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n",
        "\n",
        "            return log_spec\n",
        "\n",
        "        spectrograms = tf.signal.stft(waveforms,\n",
        "                                      frame_length=self.fft_size,\n",
        "                                      frame_step=self.hop_size,\n",
        "                                      pad_end=False)\n",
        "\n",
        "        magnitude_spectrograms = tf.abs(spectrograms)\n",
        "\n",
        "        mel_spectrograms = tf.matmul(tf.square(magnitude_spectrograms),\n",
        "                                     self.mel_filterbank)\n",
        "\n",
        "        log_mel_spectrograms = power_to_db(mel_spectrograms)\n",
        "\n",
        "        # add channel dimension\n",
        "        log_mel_spectrograms = tf.expand_dims(log_mel_spectrograms, 3)\n",
        "\n",
        "        return log_mel_spectrograms\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'fft_size': self.fft_size,\n",
        "            'hop_size': self.hop_size,\n",
        "            'n_mels': self.n_mels,\n",
        "            'sample_rate': self.sample_rate,\n",
        "            'f_min': self.f_min,\n",
        "            'f_max': self.f_max,\n",
        "        }\n",
        "        config.update(super(LogMelSpectrogram, self).get_config())\n",
        "\n",
        "        return config"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVNuBhwXXjyk"
      },
      "source": [
        "## CTC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNm-rzCqX3go"
      },
      "source": [
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2MxhB4SX8U8"
      },
      "source": [
        "def input_lengths_lambda_func(args):\n",
        "    input_length = args\n",
        "    return tf.cast(tf.math.floor(input_length/hop_size)-1, dtype=\"float32\")"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jzYXyV3YB_B"
      },
      "source": [
        "def add_ctc_loss(model_builder):\n",
        "    the_labels      = Input(name='the_labels',      shape=(None,), dtype='float32')\n",
        "    input_lengths   = Input(name='input_length',    shape=(1,), dtype='float32')\n",
        "    label_lengths   = Input(name='label_length',    shape=(1,), dtype='float32')\n",
        "\n",
        "    input_lengths2 = Lambda(input_lengths_lambda_func)(input_lengths)\n",
        "    if model_builder.output_length:\n",
        "         output_lengths  = Lambda(model_builder.output_length)(input_lengths2)\n",
        "    else:\n",
        "         output_lengths  = input_lengths2\n",
        "    \n",
        "    # CTC loss is implemented in a lambda layer\n",
        "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([model_builder.output, the_labels, output_lengths, label_lengths])\n",
        "    model = Model( inputs=[model_builder.input, the_labels, input_lengths, label_lengths],  outputs=loss_out)\n",
        "    return model"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhrONKzmYGhY"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKxnAGWeYr7l"
      },
      "source": [
        "def preprocessin_model(sample_rate, fft_size, frame_step, n_mels, mfcc=False):\n",
        "\n",
        "    input_data = Input(name='input', shape=(None,), dtype=\"float32\")\n",
        "    featLayer = LogMelSpectrogram(\n",
        "        fft_size=fft_size,\n",
        "        hop_size=frame_step,\n",
        "        n_mels=n_mels,\n",
        "        \n",
        "        sample_rate=sample_rate,\n",
        "        f_min=0.0,\n",
        "        \n",
        "        f_max=int(sample_rate / 2)\n",
        "    )(input_data)\n",
        "    \n",
        "    x = BatchNormalization()(featLayer)\n",
        "    model = Model(inputs=input_data, outputs=x, name=\"preprocessin_model\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaSgydvfYwnd"
      },
      "source": [
        "def simple_rnn_model(input_dim, output_dim=224):\n",
        "\n",
        "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
        "    simp_rnn = GRU(output_dim, return_sequences=True,\n",
        "                   implementation=2, name='rnn')(input_data)\n",
        "    y_pred = Activation('softmax', name='softmax')(simp_rnn)\n",
        "    model = Model(inputs=input_data, outputs=y_pred, name=\"simple_rnn_model\")\n",
        "    model.output_length = lambda x: x\n",
        "    return model"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM2PQVaSY0z1"
      },
      "source": [
        "def train(model_builder, \n",
        "          data_gen,\n",
        "          epochs, \n",
        "          verbose=1,\n",
        "          optimizer=SGD(learning_rate=0.002, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\n",
        "          ):    \n",
        "              \n",
        "    model = add_ctc_loss(model_builder)\n",
        "\n",
        "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
        "    print(model.summary())\n",
        "\n",
        "\n",
        "    hist = model.fit_generator(generator=data_gen,\n",
        "                               epochs=epochs,\n",
        "                               verbose=verbose, \n",
        "                               use_multiprocessing=False)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gguldrk_ciyx"
      },
      "source": [
        "## Model Trainig"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OOQUWGwcl2U"
      },
      "source": [
        "sample_rate = 16000\n",
        "fft_size = 1024\n",
        "frame_step = 512\n",
        "n_mels = 128\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 1\n",
        "data_len = len(clean_txts)\n",
        "output_dim = len(char_map) + 2\n"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGvtmfgucrvU"
      },
      "source": [
        "dg = DataGenerator(sample_audios, clean_txts, batch_size)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvUVD-Y9ctlP",
        "outputId": "022539fe-06f3-4cca-d444-9fdd65695da7"
      },
      "source": [
        "preprocess_model = preprocessin_model(sample_rate, fft_size, frame_step, n_mels)\n",
        "preprocess_model.summary()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"preprocessin_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "log_mel_spectrogram_1 (LogMe (None, None, 128, 1)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, None, 128, 1)      4         \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 2\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FyQLOaJcxN-",
        "outputId": "ca463d2e-7469-4908-b261-c0356830fda4"
      },
      "source": [
        "speech_model = simple_rnn_model(n_mels, output_dim)\n",
        "speech_model.summary()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"simple_rnn_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "the_input (InputLayer)       [(None, None, 128)]       0         \n",
            "_________________________________________________________________\n",
            "rnn (GRU)                    (None, None, 30)          14400     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, None, 30)          0         \n",
            "=================================================================\n",
            "Total params: 14,400\n",
            "Trainable params: 14,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raZU4Q6Cc4r-"
      },
      "source": [
        "def build_model(output_dim, custom_model, preprocess_model, mfcc=False, calc=None):\n",
        "\n",
        "    input_audios = Input(name='the_input', shape=(None,))\n",
        "    pre = preprocess_model(input_audios)\n",
        "    pre = tf.squeeze(pre, [3])\n",
        "\n",
        "    y_pred = custom_model(pre)\n",
        "    model = Model(inputs=input_audios, outputs=y_pred, name=\"model_builder\")\n",
        "    model.output_length = calc\n",
        "\n",
        "    return model"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w_JzuhUc6Gl",
        "outputId": "163fed89-8ecd-48c4-9517-52f4a6f557f4"
      },
      "source": [
        "model = build_model(output_dim, speech_model, preprocess_model)\n",
        "model.summary()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_builder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "the_input (InputLayer)       [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "preprocessin_model (Function (None, None, 128, 1)      4         \n",
            "_________________________________________________________________\n",
            "tf.compat.v1.squeeze_1 (TFOp (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_model (Functional (None, None, 30)          14400     \n",
            "=================================================================\n",
            "Total params: 14,404\n",
            "Trainable params: 14,402\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gI7Pq3bdCtM"
      },
      "source": [
        "#!pip install mlflow\n",
        "import mlflow\n",
        "import mlflow.tensorflow"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L_v7Y1zeDMy",
        "outputId": "94e35a1b-ddeb-4473-a056-53b45a6e92b5"
      },
      "source": [
        "\n",
        "#mlflow.set_experiment('Speech model simple rnn')\n",
        "mlflow.tensorflow.autolog()\n",
        "hop_size = 512\n",
        "train(model, dg, epochs=10)\n",
        "\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "2021/08/12 07:51:35 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.7/dist-packages/mlflow/utils/autologging_utils/safety.py:216: UserWarning: Logging to MLflow failed: 'NoneType' object does not support item assignment\"\n",
            "2021/08/12 07:51:35 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: 'NoneType' object does not support item assignment\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input (InputLayer)          [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "preprocessin_model (Functional) (None, None, 128, 1) 4           the_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.squeeze_1 (TFOpLam (None, None, 128)    0           preprocessin_model[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "input_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "simple_rnn_model (Functional)   (None, None, 30)     14400       tf.compat.v1.squeeze_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "the_labels (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 1)            0           input_length[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "label_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc (Lambda)                    (None, 1)            0           simple_rnn_model[0][0]           \n",
            "                                                                 the_labels[0][0]                 \n",
            "                                                                 lambda_2[0][0]                   \n",
            "                                                                 label_length[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 14,404\n",
            "Trainable params: 14,402\n",
            "Non-trainable params: 2\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 11s 1s/step - loss: 378.6898\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 326.0682\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 274.6424\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 249.2516\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 240.2154\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 236.9304\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 235.4127\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 234.8202\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 234.3654\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 234.2271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjgM33P_tOf-"
      },
      "source": [
        "!pip install mlflow --quiet\n",
        "#get_ipython().system_raw(\"mlflow ui --port 5000 &\")"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmOu3R97uuPu"
      },
      "source": [
        "import mlflow\n",
        "import mlflow.tensorflow"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWx6YOZ6u7D5",
        "outputId": "f8a653e4-341a-4034-b414-9bceb04dfdc3"
      },
      "source": [
        "print(mlflow.__version__)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.19.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpeL5tKcxBvC",
        "outputId": "11e3fc7e-5471-49ff-e10f-d62c48e61bcc"
      },
      "source": [
        "#mlflow.set_experiment('Speech model simple rnn')\n",
        "mlflow.tensorflow.autolog()\n",
        "hop_size = 512\n",
        "train(model, dg, epochs=10)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "2021/08/12 07:53:07 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.7/dist-packages/mlflow/utils/autologging_utils/safety.py:216: UserWarning: Logging to MLflow failed: 'NoneType' object does not support item assignment\"\n",
            "2021/08/12 07:53:07 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: 'NoneType' object does not support item assignment\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input (InputLayer)          [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "preprocessin_model (Functional) (None, None, 128, 1) 4           the_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.squeeze_1 (TFOpLam (None, None, 128)    0           preprocessin_model[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "input_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "simple_rnn_model (Functional)   (None, None, 30)     14400       tf.compat.v1.squeeze_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "the_labels (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 1)            0           input_length[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "label_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc (Lambda)                    (None, 1)            0           simple_rnn_model[0][0]           \n",
            "                                                                 the_labels[0][0]                 \n",
            "                                                                 lambda_3[0][0]                   \n",
            "                                                                 label_length[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 14,404\n",
            "Trainable params: 14,402\n",
            "Non-trainable params: 2\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 1s/step - loss: 234.0693\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 233.9431\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 233.7509\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 233.6012\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 233.4284\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 233.3565\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 233.3007\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 233.1760\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 233.0035\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 232.8564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhAlA0zmyKrD"
      },
      "source": [
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\")\n"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2yeMeR4yOZ9",
        "outputId": "0498faca-0308-449a-af32-5aba51999811"
      },
      "source": [
        "# create remote tunnel using ngrok.com to allow local port access\n",
        "# borrowed from https://colab.research.google.com/github/alfozan/MLflow-GBRT-demo/blob/master/MLflow-GBRT-demo.ipynb#scrollTo=4h3bKHMYUIG6\n",
        "!pip install pyngrok --quiet\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"1wapFvhRg5H9n37F6O6lPlJkQR4_7284vGstG3Z6uBEpkYCZJ\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "public_url = ngrok.connect(port=\"5000\", proto=\"http\", options={\"bind_tls\": True})\n",
        "print(\"MLflow Tracking UI:\", public_url)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLflow Tracking UI: NgrokTunnel: \"http://ceeab3c899e8.ngrok.io\" -> \"http://localhost:80\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIzEIUDsZ82t",
        "outputId": "d96fe8bb-e6b9-4ef0-ef7e-08cc3c8d4a9d"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.7/dist-packages (0.86.0)\n",
            "Requirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.1.5)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n",
            "Requirement already satisfied: base58 in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.19.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.2.0)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.6.2)\n",
            "Requirement already satisfied: blinker in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.18.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.1.18)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.1)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.17.3)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.1.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit) (4.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit) (3.7.4.3)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit) (4.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2018.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (1.15.0)\n",
            "Requirement already satisfied: ipykernel>=5.1.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (6.0.3)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
            "Requirement already satisfied: ipython<8.0,>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (7.26.0)\n",
            "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: jupyter-client<7.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.1.2)\n",
            "Requirement already satisfied: importlib-metadata<4 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.5.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (57.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.0.19)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.18.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (22.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.7.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.10.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUw8B8H2aJ65",
        "outputId": "243fe9ad-3aae-4674-a8bc-2bb8ef56f08b"
      },
      "source": [
        "!pip install pyngrok"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.7/dist-packages (5.0.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (5.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6-lswKQaZie",
        "outputId": "e5d74fec-07d0-412a-9101-769725c56400"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "# To make things easier later, we're also importing numpy and pandas for\n",
        "# working with sample data.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "st.title('My first app')"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0kXB-QwbtCg",
        "outputId": "914a02af-8cc8-4574-ff22-f2dd53a1f73d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "app.py\tdrive  mlruns  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_IHoav0b5df",
        "outputId": "35f70470-129e-4b37-c8a8-e6788f2bf306"
      },
      "source": [
        "!ngrok authtoken 1wapFvhRg5H9n37F6O6lPlJkQR4_7284vGstG3Z6uBEpkYCZJ"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoTySQNQckdW"
      },
      "source": [
        "from pyngrok import ngrok"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNDyZva2dc6a",
        "outputId": "43c204e4-78f0-492a-dfdc-0a967b732ff0"
      },
      "source": [
        "!pgrep streamlit"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "519\n",
            "749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eBiqfzidCJ_"
      },
      "source": [
        "!streamlit run app.py&>/dev/null&"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgDFSjwGcyu-"
      },
      "source": [
        "public_url = ngrok.connect(port=\"8080\")"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZrU89cZd0VY",
        "outputId": "fdb58b4e-8829-41cb-d690-bb786a0e4f7c"
      },
      "source": [
        "public_url"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://a24287f9980f.ngrok.io\" -> \"http://localhost:80\">"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    }
  ]
}