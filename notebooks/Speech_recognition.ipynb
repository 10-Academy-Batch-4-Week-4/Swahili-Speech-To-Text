{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech_recognition.ipynb",
      "provenance": [],
      "mount_file_id": "1uDiqF1pXtBw8fDOxga0Senknfb9YZkrH",
      "authorship_tag": "ABX9TyNfxWZEmp6Ye1Tk4kvHunlw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miz-ab/Swahili-Speech-To-Text/blob/main/notebooks/Speech_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T0xbhbtnlER",
        "outputId": "27c02d0b-4fcb-485a-9770-761781f3208a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcGz6pKXqne2",
        "outputId": "f0c157ea-e37b-43bc-e70c-28683afb9be5"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Week-4/speech_data/ALFFA_PUBLIC/ASR/SWAHILI\")\n",
        "os.listdir()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LM', 'README', 'data', 'kaldi-scripts', 'lang']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1epqE7Gq_K1"
      },
      "source": [
        "!pip install python_speech_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kcC16SHQ_8C"
      },
      "source": [
        "!pip install mlflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8HsIZ5lRYhC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import soundfile\n",
        "import json\n",
        "\n",
        "import random\n",
        "from python_speech_features import mfcc\n",
        "import librosa\n",
        "import scipy.io.wavfile as wav\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import (BatchNormalization, Conv1D, Dense, Input, \n",
        "    TimeDistributed, Activation, Bidirectional, SimpleRNN, GRU, LSTM)\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "\n",
        "import _pickle as pickle\n",
        "from numpy.lib.stride_tricks import as_strided\n",
        "\n",
        "from keras.layers import (Input, Lambda)\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint   \n",
        "import os"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mymcuAo86UI"
      },
      "source": [
        "supported = \"\"\"\n",
        "          a b c d e f\n",
        "          g h i j k l \n",
        "          m n o p q r\n",
        "          s t u v w x y z\n",
        "\"\"\".split()\n",
        "\n",
        "char_map = {}\n",
        "char_map[\"\"] = 0\n",
        "char_map[\"<SPACE>\"] = 1\n",
        "index = 2\n",
        "for c in supported:\n",
        "    char_map[c] = index\n",
        "    index += 1\n",
        "index_map = {v+1: k for k, v in char_map.items()}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqFG4rG6a9go"
      },
      "source": [
        "char_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thUQsF_K6fmG"
      },
      "source": [
        "def calc_feat_dim(window, max_freq):\n",
        "    return int(0.001 * window * max_freq) + 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i2BAHb76foo"
      },
      "source": [
        "def spectrogram(samples, fft_length=256, sample_rate=2, hop_length=128):\n",
        "    \"\"\"\n",
        "    Compute the spectrogram for a real signal.\n",
        "    The parameters follow the naming convention of\n",
        "    matplotlib.mlab.specgram\n",
        "\n",
        "    Args:\n",
        "        samples (1D array): input audio signal\n",
        "        fft_length (int): number of elements in fft window\n",
        "        sample_rate (scalar): sample rate\n",
        "        hop_length (int): hop length (relative offset between neighboring\n",
        "            fft windows).\n",
        "\n",
        "    Returns:\n",
        "        x (2D array): spectrogram [frequency x time]\n",
        "        freq (1D array): frequency of each row in x\n",
        "\n",
        "    Note:\n",
        "        This is a truncating computation e.g. if fft_length=10,\n",
        "        hop_length=5 and the signal has 23 elements, then the\n",
        "        last 3 elements will be truncated.\n",
        "    \"\"\"\n",
        "    assert not np.iscomplexobj(samples), \"Must not pass in complex numbers\"\n",
        "\n",
        "    window = np.hanning(fft_length)[:, None]\n",
        "    window_norm = np.sum(window**2)\n",
        "\n",
        "    # The scaling below follows the convention of\n",
        "    # matplotlib.mlab.specgram which is the same as\n",
        "    # matlabs specgram.\n",
        "    scale = window_norm * sample_rate\n",
        "\n",
        "    trunc = (len(samples) - fft_length) % hop_length\n",
        "    x = samples[:len(samples) - trunc]\n",
        "\n",
        "    # \"stride trick\" reshape to include overlap\n",
        "    nshape = (fft_length, (len(x) - fft_length) // hop_length + 1)\n",
        "    nstrides = (x.strides[0], x.strides[0] * hop_length)\n",
        "    x = as_strided(x, shape=nshape, strides=nstrides)\n",
        "\n",
        "    # window stride sanity check\n",
        "    assert np.all(x[:, 1] == samples[hop_length:(hop_length + fft_length)])\n",
        "\n",
        "    # broadcast window, compute fft over columns and square mod\n",
        "    x = np.fft.rfft(x * window, axis=0)\n",
        "    x = np.absolute(x)**2\n",
        "\n",
        "    # scale, 2.0 for everything except dc and fft_length/2\n",
        "    x[1:-1, :] *= (2.0 / scale)\n",
        "    x[(0, -1), :] /= scale\n",
        "\n",
        "    freqs = float(sample_rate) / fft_length * np.arange(x.shape[0])\n",
        "\n",
        "    return x, freqs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x30Os-Pi8bdT"
      },
      "source": [
        "def spectrogram_from_file(filename, step=10, window=20, max_freq=None,\n",
        "                          eps=1e-14):\n",
        "    \"\"\" Calculate the log of linear spectrogram from FFT energy\n",
        "    Params:\n",
        "        filename (str): Path to the audio file\n",
        "        step (int): Step size in milliseconds between windows\n",
        "        window (int): FFT window size in milliseconds\n",
        "        max_freq (int): Only FFT bins corresponding to frequencies between\n",
        "            [0, max_freq] are returned\n",
        "        eps (float): Small value to ensure numerical stability (for ln(x))\n",
        "    \"\"\"\n",
        "    with soundfile.SoundFile(filename) as sound_file:\n",
        "        audio = sound_file.read(dtype='float32')\n",
        "        sample_rate = sound_file.samplerate\n",
        "        if audio.ndim >= 2:\n",
        "            audio = np.mean(audio, 1)\n",
        "        if max_freq is None:\n",
        "            max_freq = sample_rate / 2\n",
        "        if max_freq > sample_rate / 2:\n",
        "            raise ValueError(\"max_freq must not be greater than half of \"\n",
        "                             \" sample rate\")\n",
        "        if step > window:\n",
        "            raise ValueError(\"step size must not be greater than window size\")\n",
        "        hop_length = int(0.001 * step * sample_rate)\n",
        "        fft_length = int(0.001 * window * sample_rate)\n",
        "        pxx, freqs = spectrogram(\n",
        "            audio, fft_length=fft_length, sample_rate=sample_rate,\n",
        "            hop_length=hop_length)\n",
        "        ind = np.where(freqs <= max_freq)[0][-1] + 1\n",
        "    return np.transpose(np.log(pxx[:ind, :] + eps))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9nJ78TV8X-b"
      },
      "source": [
        "def text_to_int_sequence(text):\n",
        "    \"\"\" Convert text to an integer sequence \"\"\"\n",
        "    int_sequence = []\n",
        "    for c in text:\n",
        "        if c == ' ':\n",
        "            ch = char_map['<SPACE>']\n",
        "        else:\n",
        "            # print(\"checking character \" + c + \" in map:\")\n",
        "            # print(char_map)\n",
        "            ch = char_map[c]\n",
        "        int_sequence.append(ch)\n",
        "    return int_sequence"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y39Q5Bq6frJ"
      },
      "source": [
        "def int_sequence_to_text(int_sequence):\n",
        "    \"\"\" Convert an integer sequence to text \"\"\"\n",
        "    text = []\n",
        "    for c in int_sequence:\n",
        "        ch = index_map[c]\n",
        "        text.append(ch)\n",
        "    return text"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI0GcAAT-Rrj"
      },
      "source": [
        "# Code adapted from https://martin-thoma.com/word-error-rate-calculation/\n",
        "def wer(r, h):\n",
        "    \"\"\"\n",
        "    Calculation of WER with Levenshtein distance.\n",
        "\n",
        "    Works only for iterables up to 254 elements (uint8).\n",
        "    O(nm) time ans space complexity.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    r : list\n",
        "    h : list\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> wer(\"who is there\".split(), \"is there\".split())\n",
        "    1\n",
        "    >>> wer(\"who is there\".split(), \"\".split())\n",
        "    3\n",
        "    >>> wer(\"\".split(), \"who is there\".split())\n",
        "    3\n",
        "    \"\"\"\n",
        "    # initialisation\n",
        "    import numpy\n",
        "    d = numpy.zeros((len(r)+1)*(len(h)+1), dtype=numpy.uint8)\n",
        "    d = d.reshape((len(r)+1, len(h)+1))\n",
        "    for i in range(len(r)+1):\n",
        "        for j in range(len(h)+1):\n",
        "            if i == 0:\n",
        "                d[0][j] = j\n",
        "            elif j == 0:\n",
        "                d[i][0] = i\n",
        "\n",
        "    # computation\n",
        "    for i in range(1, len(r)+1):\n",
        "        for j in range(1, len(h)+1):\n",
        "            if r[i-1] == h[j-1]:\n",
        "                d[i][j] = d[i-1][j-1]\n",
        "            else:\n",
        "                substitution = d[i-1][j-1] + 1\n",
        "                insertion    = d[i][j-1] + 1\n",
        "                deletion     = d[i-1][j] + 1\n",
        "                d[i][j] = min(substitution, insertion, deletion)\n",
        "\n",
        "    return d[len(r)][len(h)]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUNs2EnD-bp4"
      },
      "source": [
        "\"\"\"\n",
        "Helper functions for plotting\n",
        "\"\"\"\n",
        "\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_hist(p):\n",
        "    hist = pickle.load(open( \"models/\" + p + \".pickle\", \"rb\"))\n",
        "    plt.plot(hist['loss'], label=\"train\")\n",
        "    plt.plot(hist['val_loss'], label=\"valid\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.legend()\n",
        "    plt.show"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIOW4LtIcPfx"
      },
      "source": [
        "## Input data generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ppo9xbg9yGB"
      },
      "source": [
        "\n",
        "RNG_SEED = 123\n",
        "\n",
        "def make_audio_gen(train_json,\n",
        "                   valid_json,\n",
        "                   minibatch_size=20,\n",
        "                   spectrogram=True,\n",
        "                   mfcc_dim=13,\n",
        "                   sort_by_duration=False,\n",
        "                   max_duration=10.0):\n",
        "    return AudioGenerator(train_json, valid_json, minibatch_size=minibatch_size, \n",
        "        spectrogram=spectrogram, mfcc_dim=mfcc_dim, max_duration=max_duration,\n",
        "        sort_by_duration=sort_by_duration)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpMCkLEP6ft2"
      },
      "source": [
        "\"\"\"\n",
        "Defines a class that is used to featurize audio clips, and provide\n",
        "them to the network for training or testing.\n",
        "\"\"\"\n",
        "class AudioGenerator():\n",
        "    def __init__(self, train_corpus, valid_corpus, step=10, window=20, max_freq=8000, mfcc_dim=13,\n",
        "        minibatch_size=20, desc_file=None, spectrogram=True, max_duration=10.0, \n",
        "        sort_by_duration=False):\n",
        "        \"\"\"\n",
        "        Params:\n",
        "            step (int): Step size in milliseconds between windows (for spectrogram ONLY)\n",
        "            window (int): FFT window size in milliseconds (for spectrogram ONLY)\n",
        "            max_freq (int): Only FFT bins corresponding to frequencies between\n",
        "                [0, max_freq] are returned (for spectrogram ONLY)\n",
        "            desc_file (str, optional): Path to a JSON-line file that contains\n",
        "                labels and paths to the audio files. If this is None, then\n",
        "                load metadata right away\n",
        "        \"\"\"\n",
        "        self.train_corpus = train_corpus\n",
        "        self.valid_corpus = valid_corpus\n",
        "        self.feat_dim = calc_feat_dim(window, max_freq)\n",
        "        self.mfcc_dim = mfcc_dim\n",
        "        self.feats_mean = np.zeros((self.feat_dim,))\n",
        "        self.feats_std = np.ones((self.feat_dim,))\n",
        "        self.rng = random.Random(RNG_SEED)\n",
        "        if desc_file is not None:\n",
        "            self.load_metadata_from_desc_file(desc_file)\n",
        "        self.step = step\n",
        "        self.window = window\n",
        "        self.max_freq = max_freq\n",
        "        self.cur_train_index = 0\n",
        "        self.cur_valid_index = 0\n",
        "        self.cur_test_index = 0\n",
        "        self.max_duration=max_duration\n",
        "        self.minibatch_size = minibatch_size\n",
        "        self.spectrogram = spectrogram\n",
        "        self.sort_by_duration = sort_by_duration\n",
        "\n",
        "    def get_batch(self, partition):\n",
        "        \"\"\" Obtain a batch of train, validation, or test data\n",
        "        \"\"\"\n",
        "        if partition == 'train':\n",
        "            audio_paths = self.train_audio_paths\n",
        "            cur_index = self.cur_train_index\n",
        "            texts = self.train_texts\n",
        "        elif partition == 'valid':\n",
        "            audio_paths = self.valid_audio_paths\n",
        "            cur_index = self.cur_valid_index\n",
        "            texts = self.valid_texts\n",
        "        elif partition == 'test':\n",
        "            audio_paths = self.test_audio_paths\n",
        "            cur_index = self.test_valid_index\n",
        "            texts = self.test_texts\n",
        "        else:\n",
        "            raise Exception(\"Invalid partition. \"\n",
        "                \"Must be train/validation\")\n",
        "\n",
        "        features = [self.normalize(self.featurize(a)) for a in \n",
        "            audio_paths[cur_index:cur_index+self.minibatch_size]]\n",
        "\n",
        "        # calculate necessary sizes\n",
        "        max_length = max([features[i].shape[0] \n",
        "            for i in range(0, self.minibatch_size)])\n",
        "        max_string_length = max([len(texts[cur_index+i]) \n",
        "            for i in range(0, self.minibatch_size)])\n",
        "        \n",
        "        # initialize the arrays\n",
        "        X_data = np.zeros([self.minibatch_size, max_length, \n",
        "            self.feat_dim*self.spectrogram + self.mfcc_dim*(not self.spectrogram)])\n",
        "        labels = np.ones([self.minibatch_size, max_string_length]) * 28\n",
        "        input_length = np.zeros([self.minibatch_size, 1])\n",
        "        label_length = np.zeros([self.minibatch_size, 1])\n",
        "        \n",
        "        for i in range(0, self.minibatch_size):\n",
        "            # calculate X_data & input_length\n",
        "            feat = features[i]\n",
        "            input_length[i] = feat.shape[0]\n",
        "            X_data[i, :feat.shape[0], :] = feat\n",
        "\n",
        "            # calculate labels & label_length\n",
        "            label = np.array(text_to_int_sequence(texts[cur_index+i])) \n",
        "            labels[i, :len(label)] = label\n",
        "            label_length[i] = len(label)\n",
        " \n",
        "        # return the arrays\n",
        "        outputs = {'ctc': np.zeros([self.minibatch_size])}\n",
        "        inputs = {'the_input': X_data, \n",
        "                  'the_labels': labels, \n",
        "                  'input_length': input_length, \n",
        "                  'label_length': label_length \n",
        "                 }\n",
        "        return (inputs, outputs)\n",
        "\n",
        "    def shuffle_data_by_partition(self, partition):\n",
        "        \"\"\" Shuffle the training or validation data\n",
        "        \"\"\"\n",
        "        if partition == 'train':\n",
        "            self.train_audio_paths, self.train_durations, self.train_texts = shuffle_data(\n",
        "                self.train_audio_paths, self.train_durations, self.train_texts)\n",
        "            self.train_length = len(self.train_texts)\n",
        "        elif partition == 'valid':\n",
        "            self.valid_audio_paths, self.valid_durations, self.valid_texts = shuffle_data(\n",
        "                self.valid_audio_paths, self.valid_durations, self.valid_texts)\n",
        "            self.valid_length = len(self.valid_texts)\n",
        "        else:\n",
        "            raise Exception(\"Invalid partition. \"\n",
        "                \"Must be train/validation\")\n",
        "\n",
        "    def sort_data_by_duration(self, partition):\n",
        "        \"\"\" Sort the training or validation sets by (increasing) duration\n",
        "        \"\"\"\n",
        "        if partition == 'train':\n",
        "            self.train_audio_paths, self.train_durations, self.train_texts = sort_data(\n",
        "                self.train_audio_paths, self.train_durations, self.train_texts)\n",
        "        elif partition == 'valid':\n",
        "            self.valid_audio_paths, self.valid_durations, self.valid_texts = sort_data(\n",
        "                self.valid_audio_paths, self.valid_durations, self.valid_texts)\n",
        "        else:\n",
        "            raise Exception(\"Invalid partition. \"\n",
        "                \"Must be train/validation\")\n",
        "\n",
        "    def next_train(self):\n",
        "        \"\"\" Obtain a batch of training data\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            ret = self.get_batch('train')\n",
        "            self.cur_train_index += self.minibatch_size\n",
        "            if self.cur_train_index >= len(self.train_texts) - self.minibatch_size:\n",
        "                self.cur_train_index = 0\n",
        "                self.shuffle_data_by_partition('train')\n",
        "            yield ret    \n",
        "\n",
        "    def next_valid(self):\n",
        "        \"\"\" Obtain a batch of validation data\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            ret = self.get_batch('valid')\n",
        "            self.cur_valid_index += self.minibatch_size\n",
        "            if self.cur_valid_index >= len(self.valid_texts) - self.minibatch_size:\n",
        "                self.cur_valid_index = 0\n",
        "                self.shuffle_data_by_partition('valid')\n",
        "            yield ret\n",
        "\n",
        "    def next_test(self):\n",
        "        \"\"\" Obtain a batch of test data\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            ret = self.get_batch('test')\n",
        "            self.cur_test_index += self.minibatch_size\n",
        "            if self.cur_test_index >= len(self.test_texts) - self.minibatch_size:\n",
        "                self.cur_test_index = 0\n",
        "            yield ret\n",
        "\n",
        "    def load_train_data(self):\n",
        "        desc_file=self.train_corpus\n",
        "        self.load_metadata_from_desc_file(desc_file, 'train')\n",
        "        self.fit_train()\n",
        "        if self.sort_by_duration:\n",
        "            self.sort_data_by_duration('train')\n",
        "\n",
        "    def load_validation_data(self):\n",
        "        desc_file=self.valid_corpus\n",
        "        self.load_metadata_from_desc_file(desc_file, 'validation')\n",
        "        if self.sort_by_duration:\n",
        "            self.sort_data_by_duration('valid')\n",
        "\n",
        "    def load_test_data(self):\n",
        "        desc_file='test_corpus.json'\n",
        "        self.load_metadata_from_desc_file(desc_file, 'test')\n",
        "    \n",
        "    def load_metadata_from_desc_file(self, desc_file, partition):\n",
        "        \"\"\" Read metadata from a JSON-line file\n",
        "            (possibly takes long, depending on the filesize)\n",
        "        Params:\n",
        "            desc_file (str):  Path to a JSON-line file that contains labels and\n",
        "                paths to the audio files\n",
        "            partition (str): One of 'train', 'validation' or 'test'\n",
        "        \"\"\"\n",
        "        audio_paths, durations, texts = [], [], []\n",
        "        with open(desc_file, encoding='utf-8') as json_line_file:\n",
        "            for line_num, json_line in enumerate(json_line_file):\n",
        "                try:\n",
        "                    spec = json.loads(json_line)\n",
        "                    if float(spec['duration']) > self.max_duration:\n",
        "                        continue\n",
        "                    audio_paths.append(spec['key'])\n",
        "                    durations.append(float(spec['duration']))\n",
        "                    texts.append(spec['text'])\n",
        "                except Exception as e:\n",
        "                    # Change to (KeyError, ValueError) or\n",
        "                    # (KeyError,json.decoder.JSONDecodeError), depending on\n",
        "                    # json module version\n",
        "                    print('Error reading line #{}: {}'\n",
        "                                .format(line_num, json_line))\n",
        "        if partition == 'train':\n",
        "            self.train_audio_paths = audio_paths\n",
        "            self.train_durations = durations\n",
        "            self.train_texts = texts\n",
        "        elif partition == 'validation':\n",
        "            self.valid_audio_paths = audio_paths\n",
        "            self.valid_durations = durations\n",
        "            self.valid_texts = texts\n",
        "        elif partition == 'test':\n",
        "            self.test_audio_paths = audio_paths\n",
        "            self.test_durations = durations\n",
        "            self.test_texts = texts\n",
        "        else:\n",
        "            raise Exception(\"Invalid partition to load metadata. \"\n",
        "             \"Must be train/validation/test\")\n",
        "            \n",
        "    def fit_train(self, k_samples=100):\n",
        "        \"\"\" Estimate the mean and std of the features from the training set\n",
        "        Params:\n",
        "            k_samples (int): Use this number of samples for estimation\n",
        "        \"\"\"\n",
        "        k_samples = min(k_samples, len(self.train_audio_paths))\n",
        "        samples = self.rng.sample(self.train_audio_paths, k_samples)\n",
        "        feats = [self.featurize(s) for s in samples]\n",
        "        feats = np.vstack(feats)\n",
        "        self.feats_mean = np.mean(feats, axis=0)\n",
        "        self.feats_std = np.std(feats, axis=0)\n",
        "        \n",
        "    def featurize(self, audio_clip):\n",
        "        \"\"\" For a given audio clip, calculate the corresponding feature\n",
        "        Params:\n",
        "            audio_clip (str): Path to the audio clip\n",
        "        \"\"\"\n",
        "        if self.spectrogram:\n",
        "            return spectrogram_from_file(\n",
        "                audio_clip, step=self.step, window=self.window,\n",
        "                max_freq=self.max_freq)\n",
        "        else:\n",
        "            (rate, sig) = wav.read(audio_clip)\n",
        "            return mfcc(sig, rate, numcep=self.mfcc_dim)\n",
        "\n",
        "    def normalize(self, feature, eps=1e-14):\n",
        "        \"\"\" Center a feature using the mean and std\n",
        "        Params:\n",
        "            feature (numpy.ndarray): Feature to normalize\n",
        "        \"\"\"\n",
        "        return (feature - self.feats_mean) / (self.feats_std + eps)\n",
        "\n",
        "    def train_length(self):\n",
        "        return len(self.train_texts)\n",
        "    \n",
        "    def valid_length(self):\n",
        "        return len(self.valid_texts)\n",
        "\n",
        "\n",
        "def shuffle_data(audio_paths, durations, texts):\n",
        "    \"\"\" Shuffle the data (called after making a complete pass through \n",
        "        training or validation data during the training process)\n",
        "    Params:\n",
        "        audio_paths (list): Paths to audio clips\n",
        "        durations (list): Durations of utterances for each audio clip\n",
        "        texts (list): Sentences uttered in each audio clip\n",
        "    \"\"\"\n",
        "    p = np.random.permutation(len(audio_paths))\n",
        "    audio_paths = [audio_paths[i] for i in p] \n",
        "    durations = [durations[i] for i in p] \n",
        "    texts = [texts[i] for i in p]\n",
        "    return audio_paths, durations, texts\n",
        "\n",
        "def sort_data(audio_paths, durations, texts):\n",
        "    \"\"\" Sort the data by duration \n",
        "    Params:\n",
        "        audio_paths (list): Paths to audio clips\n",
        "        durations (list): Durations of utterances for each audio clip\n",
        "        texts (list): Sentences uttered in each audio clip\n",
        "    \"\"\"\n",
        "    p = np.argsort(durations).tolist()\n",
        "    audio_paths = [audio_paths[i] for i in p]\n",
        "    durations = [durations[i] for i in p] \n",
        "    texts = [texts[i] for i in p]\n",
        "    return audio_paths, durations, texts\n",
        "\n",
        "def vis_train_features(index=0):\n",
        "    \"\"\" Visualizing the data point in the training set at the supplied index\n",
        "    \"\"\"\n",
        "    # obtain spectrogram\n",
        "    audio_gen = AudioGenerator(spectrogram=True)\n",
        "    audio_gen.load_train_data()\n",
        "    vis_audio_path = audio_gen.train_audio_paths[index]\n",
        "    vis_spectrogram_feature = audio_gen.normalize(audio_gen.featurize(vis_audio_path))\n",
        "    # obtain mfcc\n",
        "    audio_gen = AudioGenerator(spectrogram=False)\n",
        "    audio_gen.load_train_data()\n",
        "    vis_mfcc_feature = audio_gen.normalize(audio_gen.featurize(vis_audio_path))\n",
        "    # obtain text label\n",
        "    vis_text = audio_gen.train_texts[index]\n",
        "    # obtain raw audio\n",
        "    vis_raw_audio, _ = librosa.load(amharic_path(vis_audio_path))\n",
        "    # print total number of training examples\n",
        "    print('There are %d total training examples.' % len(audio_gen.train_audio_paths))\n",
        "    # return labels for plotting\n",
        "    return vis_text, vis_raw_audio, vis_mfcc_feature, vis_spectrogram_feature, vis_audio_path\n",
        "\n",
        "\n",
        "def plot_raw_audio(vis_raw_audio, title='Audio Signal', size=(12, 3)):\n",
        "    fig = plt.figure(figsize=size)\n",
        "    ax = fig.add_subplot(111)\n",
        "    steps = len(vis_raw_audio)\n",
        "    ax.plot(np.linspace(1, steps, steps), vis_raw_audio)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.show()\n",
        "\n",
        "def plot_mfcc_feature(vis_mfcc_feature):\n",
        "    # plot the MFCC feature\n",
        "    fig = plt.figure(figsize=(12,5))\n",
        "    ax = fig.add_subplot(111)\n",
        "    im = ax.imshow(vis_mfcc_feature, cmap=plt.cm.jet, aspect='auto')\n",
        "    plt.title('Normalized MFCC')\n",
        "    plt.ylabel('Time')\n",
        "    plt.xlabel('MFCC Coefficient')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    plt.colorbar(im, cax=cax)\n",
        "    ax.set_xticks(np.arange(0, 13, 2), minor=False);\n",
        "    plt.show()\n",
        "\n",
        "def plot_spectrogram_feature(vis_spectrogram_feature):\n",
        "    # plot the normalized spectrogram\n",
        "    fig = plt.figure(figsize=(12,5))\n",
        "    ax = fig.add_subplot(111)\n",
        "    im = ax.imshow(vis_spectrogram_feature, cmap=plt.cm.jet, aspect='auto')\n",
        "    plt.title('Normalized Spectrogram')\n",
        "    plt.ylabel('Time')\n",
        "    plt.xlabel('Frequency')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    plt.colorbar(im, cax=cax)\n",
        "    plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "PlDZTHrFnHSx",
        "outputId": "1989bb82-7f8b-42f8-857c-44526792fd50"
      },
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Week-4/speech_data/ALFFA_PUBLIC/ASR/SWAHILI/data/train/text.txt\",sep=\"\\t\",header=None)\n",
        "df = df.drop([0],axis=1)\n",
        "df.columns=['text']\n",
        "df.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0             rais wa tanzania jakaya mrisho kikwete\n",
              "1  yanayo andaliwa nami pendo pondo idhaa ya kisw...\n",
              "2  inayokutangazia moja kwa moja kutoka jijini da...\n",
              "3  juma hili bara la afrika limeshuhudia raia wa ...\n",
              "4    wakipiga kura ya maoni ilikufanya mabadiliko ya"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "FjzEXfYYvo_1",
        "outputId": "c696ad6d-5a53-4a02-db82-277c24953c99"
      },
      "source": [
        "import itertools\n",
        "limit = 30\n",
        "for index, row in itertools.islice(df.iterrows(), limit):\n",
        "  df = df.drop([0],axis=1)\n",
        "  df.columns=['text_']"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-4052c78f1710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4172\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4174\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m         )\n\u001b[1;32m   4176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3889\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3922\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3923\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '[0] not found in axis'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2Uichg_n-Ns",
        "outputId": "9b82c909-675f-4661-9b79-c52cf72132fe"
      },
      "source": [
        "#load the first folder in train \n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/Week-4/speech_data/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav\")\n",
        "folders = os.listdir()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddWj508mo0QL",
        "outputId": "45ade9c9-98bc-4705-be3c-a11a26742e2a"
      },
      "source": [
        "labels = []\n",
        "for file_name in folders:\n",
        "  labels.append(file_name)\n",
        "\n",
        "len(labels)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "BkDNo-aMqTYj",
        "outputId": "39ab0d94-a219-49bd-f9cf-c39e734b201d"
      },
      "source": [
        "df['audio']=labels\n",
        "df.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-bfe6da1e5454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3118\u001b[0m         \"\"\"\n\u001b[1;32m   3119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3120\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3121\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3767\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3768\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3770\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         raise ValueError(\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (30) does not match length of index (10180)"
          ]
        }
      ]
    }
  ]
}