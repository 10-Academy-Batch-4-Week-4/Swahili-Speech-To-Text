{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Speech Recognition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "import os\r\n",
    "import pickle\r\n",
    "import librosa\r\n",
    "import pandas as pd\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\r\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\r\n",
    "\r\n",
    "from IPython.display import Audio\r\n",
    "\r\n",
    "import librosa.display\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "from tensorflow.keras.models import Model, Sequential\r\n",
    "from tensorflow.keras.layers import *\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\r\n",
    "from tensorflow.keras import backend as K"
   ],
   "outputs": [],
   "metadata": {
    "id": "8DB4X_g6ovq6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "rows = []\r\n",
    "parent_dir = \"../data/SWH-05-20101106\"\r\n",
    "files = os.listdir(parent_dir)\r\n",
    "for f in files:\r\n",
    "    audio, fs = librosa.load(f\"{parent_dir}/{f}\")\r\n",
    "    filename = f.split('.')[0]\r\n",
    "    row = {'filename': filename, 'audio': audio}\r\n",
    "    rows.append(row)\r\n",
    "rows[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part10',\n",
       "  'audio': array([0.02953335, 0.03225018, 0.02603412, ..., 0.09593043, 0.09478676,\n",
       "         0.05775513], dtype=float32)},\n",
       " {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part100',\n",
       "  'audio': array([ 0.00471402,  0.00630584,  0.00576152, ...,  0.01627303,\n",
       "         -0.00729037, -0.01463527], dtype=float32)},\n",
       " {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part101',\n",
       "  'audio': array([0.00886934, 0.00965257, 0.0063316 , ..., 0.22327209, 0.280469  ,\n",
       "         0.        ], dtype=float32)},\n",
       " {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part102',\n",
       "  'audio': array([-0.01096754, -0.01230842, -0.01015999, ..., -0.21667908,\n",
       "         -0.20379573, -0.11009098], dtype=float32)},\n",
       " {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part103',\n",
       "  'audio': array([0.01063866, 0.01384298, 0.01281647, ..., 0.0591335 , 0.05393954,\n",
       "         0.02577941], dtype=float32)}]"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZP9qdhcRiyUG",
    "outputId": "647279b8-2180-495c-c9b5-444aad8d6f69"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "sample_audios = []\r\n",
    "for row in rows:\r\n",
    "    audio = row['audio']\r\n",
    "    sample_audios.append(audio)\r\n",
    "sample_audios[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([0.02953335, 0.03225018, 0.02603412, ..., 0.09593043, 0.09478676,\n",
       "        0.05775513], dtype=float32),\n",
       " array([ 0.00471402,  0.00630584,  0.00576152, ...,  0.01627303,\n",
       "        -0.00729037, -0.01463527], dtype=float32),\n",
       " array([0.00886934, 0.00965257, 0.0063316 , ..., 0.22327209, 0.280469  ,\n",
       "        0.        ], dtype=float32),\n",
       " array([-0.01096754, -0.01230842, -0.01015999, ..., -0.21667908,\n",
       "        -0.20379573, -0.11009098], dtype=float32),\n",
       " array([0.01063866, 0.01384298, 0.01281647, ..., 0.0591335 , 0.05393954,\n",
       "        0.02577941], dtype=float32)]"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8NByqTOUhRd",
    "outputId": "928568e2-fc8f-4100-a143-57e344e6cfc2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "meta_df = pd.read_csv('../metadata.csv')"
   ],
   "outputs": [],
   "metadata": {
    "id": "8H6faM08QvZ2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "meta_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            filename  \\\n",
       "0  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "1  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "2  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "3  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "4  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "\n",
       "                                       transcription  \\\n",
       "0             rais wa tanzania jakaya mrisho kikwete   \n",
       "1  yanayo andaliwa nami pendo pondo idhaa ya kisw...   \n",
       "2  inayokutangazia moja kwa moja kutoka jijini da...   \n",
       "3  juma hili bara la afrika limeshuhudia raia wa ...   \n",
       "4    wakipiga kura ya maoni ilikufanya mabadiliko ya   \n",
       "\n",
       "                                            filepath  sample_rate  duration  \n",
       "0  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.14  \n",
       "1  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.10  \n",
       "2  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.65  \n",
       "3  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.90  \n",
       "4  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      2.94  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>transcription</th>\n",
       "      <th>filepath</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
       "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
       "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
       "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
       "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
       "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
       "      <td>16000</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "bVVnaH5DT6DG",
    "outputId": "3a897f5c-02ae-4bd3-efc6-63bad140ca2c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "meta_df['sample_rate'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16000    10180\n",
       "Name: sample_rate, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4gKmDRi3YRo",
    "outputId": "9856621c-76fb-4165-c84c-4a0f59bc28b0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "meta_df.columns.to_list()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['filename', 'transcription', 'filepath', 'sample_rate', 'duration']"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPio4y_9RhvC",
    "outputId": "11664bc7-f4f9-4ca7-a8d8-e51082e08647"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "txts = []\r\n",
    "for row in rows:\r\n",
    "    filename = row['filename']\r\n",
    "    filter = meta_df[meta_df['filename'] == filename]\r\n",
    "    txt = filter[['transcription']].values\r\n",
    "    txts.append(txt)\r\n",
    "\r\n",
    "txts[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([['rais wa tanzania jakaya mrisho kikwete']], dtype=object),\n",
       " array([['yanayo andaliwa nami pendo pondo idhaa ya kiswahili']],\n",
       "       dtype=object),\n",
       " array([['inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania']],\n",
       "       dtype=object),\n",
       " array([['juma hili bara la afrika limeshuhudia raia wa nchi za niger']],\n",
       "       dtype=object),\n",
       " array([['wakipiga kura ya maoni ilikufanya mabadiliko ya']], dtype=object)]"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gNHLp5mHSXbT",
    "outputId": "c5016151-e276-4a32-d608-e79168d2bc17"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "txts = np.array(txts).reshape(-1)"
   ],
   "outputs": [],
   "metadata": {
    "id": "QtbOxUt-Vvzr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "txts[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['rais wa tanzania jakaya mrisho kikwete',\n",
       "       'yanayo andaliwa nami pendo pondo idhaa ya kiswahili',\n",
       "       'inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania',\n",
       "       'juma hili bara la afrika limeshuhudia raia wa nchi za niger',\n",
       "       'wakipiga kura ya maoni ilikufanya mabadiliko ya'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdRmO_PMWK7M",
    "outputId": "ac00c082-2c8a-427a-ec61-fc2127ecc6bc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "clean_txts = []\r\n",
    "alphabets = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'.split()\r\n",
    "for txt in txts:\r\n",
    "    clean_txt = []\r\n",
    "    for c in txt:\r\n",
    "        if c not in alphabets and c != ' ':\r\n",
    "            continue\r\n",
    "        clean_txt.append(c)\r\n",
    "    clean_txt = ''.join(clean_txt)\r\n",
    "    clean_txts.append(clean_txt)"
   ],
   "outputs": [],
   "metadata": {
    "id": "bj7dp_XDZFpb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "clean_txts[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['rais wa tanzania jakaya mrisho kikwete',\n",
       " 'yanayo andaliwa nami pendo pondo idhaa ya kiswahili',\n",
       " 'inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania',\n",
       " 'juma hili bara la afrika limeshuhudia raia wa nchi za niger',\n",
       " 'wakipiga kura ya maoni ilikufanya mabadiliko ya']"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hssO43laaId0",
    "outputId": "ff2a1320-85e4-4b6b-bad8-47a06097e194"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "'' in clean_txts"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "df = pd.DataFrame(clean_txts)\r\n",
    "df.columns = ['texts']\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               texts\n",
       "0             rais wa tanzania jakaya mrisho kikwete\n",
       "1  yanayo andaliwa nami pendo pondo idhaa ya kisw...\n",
       "2  inayokutangazia moja kwa moja kutoka jijini da...\n",
       "3  juma hili bara la afrika limeshuhudia raia wa ...\n",
       "4    wakipiga kura ya maoni ilikufanya mabadiliko ya"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "idxs = df[df['texts'] == ''].index\r\n",
    "idxs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Int64Index([19, 21, 56], dtype='int64')"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "del clean_txts[idxs[-1]]\r\n",
    "del clean_txts[idxs[-2]]\r\n",
    "del clean_txts[idxs[-3]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "'' in clean_txts"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "del sample_audios[idxs[-1]]\r\n",
    "del sample_audios[idxs[-2]]\r\n",
    "del sample_audios[idxs[-3]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenizer"
   ],
   "metadata": {
    "id": "P3Aa-Wdc7Rnq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "def character_dict():\r\n",
    "    alphabet = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'\r\n",
    "    supported = alphabet.split()\r\n",
    "\r\n",
    "    char_map = {}\r\n",
    "    char_map[\"\"] = 0\r\n",
    "    char_map[\"<SPACE>\"] = 1\r\n",
    "    idx = 2\r\n",
    "    for c in supported:\r\n",
    "        char_map[c] = idx\r\n",
    "        idx += 1\r\n",
    "    index_map = {v: k for k, v in char_map.items()}\r\n",
    "    return char_map, index_map"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30NG8Jgz1H56",
    "outputId": "686fe668-679b-4944-f761-902d9bcad9cf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "char_map, index_map = character_dict()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "char_map"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " '<SPACE>': 1,\n",
       " 'a': 2,\n",
       " 'b': 3,\n",
       " 'c': 4,\n",
       " 'd': 5,\n",
       " 'e': 6,\n",
       " 'f': 7,\n",
       " 'g': 8,\n",
       " 'h': 9,\n",
       " 'i': 10,\n",
       " 'j': 11,\n",
       " 'k': 12,\n",
       " 'l': 13,\n",
       " 'm': 14,\n",
       " 'n': 15,\n",
       " 'o': 16,\n",
       " 'p': 17,\n",
       " 'q': 18,\n",
       " 'r': 19,\n",
       " 's': 20,\n",
       " 't': 21,\n",
       " 'u': 22,\n",
       " 'v': 23,\n",
       " 'w': 24,\n",
       " 'x': 25,\n",
       " 'y': 26,\n",
       " 'z': 27}"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "def text_to_int_sequence(text):\r\n",
    "    \"\"\" Convert text to an integer sequence \"\"\"\r\n",
    "    int_sequence = []\r\n",
    "    for c in text:\r\n",
    "        if c == ' ':\r\n",
    "            ch = char_map['<SPACE>']\r\n",
    "        elif c in alphabets:\r\n",
    "            ch = char_map[c]\r\n",
    "        else:\r\n",
    "            print(c)\r\n",
    "            print('character not found')\r\n",
    "            break\r\n",
    "        int_sequence.append(ch)\r\n",
    "    return np.array(int_sequence)"
   ],
   "outputs": [],
   "metadata": {
    "id": "C9nJ78TV8X-b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "def int_sequence_to_text(int_sequence):\r\n",
    "    \"\"\" Convert an integer sequence to text \"\"\"\r\n",
    "    textch = []\r\n",
    "    for c in int_sequence:\r\n",
    "        ch = index_map[c]\r\n",
    "        textch.append(ch)\r\n",
    "    text = ''.join(textch)\r\n",
    "    text = text.replace('<SPACE>', ' ')\r\n",
    "    return text"
   ],
   "outputs": [],
   "metadata": {
    "id": "4y39Q5Bq6frJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Generator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\r\n",
    "    def __init__(self, audios, texts, batch_size=32):\r\n",
    "        self.audios = audios\r\n",
    "        self.texts = texts\r\n",
    "        self.batch_size = batch_size\r\n",
    "        self.steps = int(len(self.audios) // self.batch_size)\r\n",
    "        # self.index = 0\r\n",
    "        self.on_epoch_end()\r\n",
    "\r\n",
    "    # def shuffle(self):\r\n",
    "    #     np.random.shuffle(self.indexes)\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return self.steps\r\n",
    "\r\n",
    "    def on_epoch_end(self):\r\n",
    "        self.indexes = np.arange(self.steps*self.batch_size)\r\n",
    "        # np.random.shuffle(self.indexes)\r\n",
    "\r\n",
    "    def data_generation(self, batch_audios, batch_texts):\r\n",
    "\r\n",
    "        longest_audio = max([len(i) for i in batch_audios])\r\n",
    "        longest_txt = max([len(i) for i in batch_texts])\r\n",
    "\r\n",
    "        audios          = np.zeros([int(self.batch_size), longest_audio], dtype=\"float32\")\r\n",
    "        txts            = np.zeros([int(self.batch_size), longest_txt], dtype=\"int64\")\r\n",
    "        audio_length    = np.zeros([int(self.batch_size)], dtype=\"int64\")\r\n",
    "        txt_length      = np.zeros([int(self.batch_size)], dtype=\"int64\")\r\n",
    "\r\n",
    "        i = 0\r\n",
    "        for audio, txt in zip(batch_audios, batch_texts):\r\n",
    "\r\n",
    "            txt_len = len(txt)\r\n",
    "\r\n",
    "            txt = text_to_int_sequence(txt)\r\n",
    "            # print(txts.shape)\r\n",
    "            # print(np.array(txt).shape)\r\n",
    "            txts[i,: txt_len] = txt\r\n",
    "\r\n",
    "            audio_len = len(audio)\r\n",
    "\r\n",
    "            audios[i, :audio_len] = audio\r\n",
    "\r\n",
    "            audio_length[i] = audio_len\r\n",
    "            txt_length[i] = txt_len\r\n",
    "\r\n",
    "            i+=1          \r\n",
    "            \r\n",
    "        outputs = {'ctc': np.zeros([self.batch_size])}\r\n",
    "        inputs = {\r\n",
    "                    'the_input':    tf.convert_to_tensor(audios), \r\n",
    "                    'the_labels':   tf.convert_to_tensor(txts), \r\n",
    "                    'input_length': tf.convert_to_tensor(audio_length), \r\n",
    "                    'label_length': tf.convert_to_tensor(txt_length)\r\n",
    "                }\r\n",
    "        return (inputs, outputs)\r\n",
    "\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        indexes = self.indexes[int(index*self.batch_size):int((index+1)*self.batch_size)]\r\n",
    "    \r\n",
    "        batch_audios = [self.audios[int(i)] for i in indexes]\r\n",
    "        batch_texts = [self.texts[int(i)] for i in indexes]\r\n",
    "        \r\n",
    "        return  self.data_generation(batch_audios, batch_texts)"
   ],
   "outputs": [],
   "metadata": {
    "id": "dmvz_Svx7U7l"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "dg = DataGenerator(sample_audios, clean_txts)"
   ],
   "outputs": [],
   "metadata": {
    "id": "FMZLj1GeQny1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "len(dg)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9yv2uTEBcWp",
    "outputId": "46ab876c-41ec-4784-ea8b-03c9de62096a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "batch1 = dg[0][0]\r\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "b2V8FZlhWdIt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "batch1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'the_input': <tf.Tensor: shape=(32, 128993), dtype=float32, numpy=\n",
       " array([[ 0.02953335,  0.03225018,  0.02603412, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.00471402,  0.00630584,  0.00576152, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.00886934,  0.00965257,  0.0063316 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [-0.01929947, -0.0214183 , -0.01492864, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.00464254,  0.00063416, -0.00608059, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.02031364, -0.02287264, -0.02081008, ...,  0.        ,\n",
       "          0.        ,  0.        ]], dtype=float32)>,\n",
       " 'the_labels': <tf.Tensor: shape=(32, 102), dtype=int64, numpy=\n",
       " array([[19,  2, 10, ...,  0,  0,  0],\n",
       "        [26,  2, 15, ...,  0,  0,  0],\n",
       "        [10, 15,  2, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [12, 22, 13, ...,  0,  0,  0],\n",
       "        [15,  2,  1, ...,  0,  0,  0],\n",
       "        [22, 13, 10, ...,  0,  0,  0]], dtype=int64)>,\n",
       " 'input_length': <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
       " array([ 69237,  68355,  80483,  85995,  64827,  54023,  57771,  54684,\n",
       "         77837,  60417, 112455,  48069,  82688,  59094, 108266,  51597,\n",
       "         50054,  72545,  52700, 112455,  58653,  92831,  75411, 128993,\n",
       "         85995,  67694,  51818,  88202,  54023,  47628,  71883,  78057],\n",
       "       dtype=int64)>,\n",
       " 'label_length': <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
       " array([ 38,  51,  66,  59,  47,  30,  44,  36,  39,  38,  94,  38,  55,\n",
       "         35,  69,  34,  36,  42,  38,  61,  52,  59,  58, 102,  65,  52,\n",
       "         34,  55,  38,  25,  40,  60], dtype=int64)>}"
      ]
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EvPWc-V09v-c",
    "outputId": "a9377aec-617b-4e23-a294-a0bbd0df73fd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LogMelSpectrogram"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "class LogMelSpectrogram(tf.keras.layers.Layer):\r\n",
    "    \"\"\"Compute log-magnitude mel-scaled spectrograms.\"\"\"\r\n",
    "\r\n",
    "    def __init__(self, sample_rate, fft_size, hop_size, n_mels,\r\n",
    "                 f_min=0.0, f_max=None, **kwargs):\r\n",
    "        super(LogMelSpectrogram, self).__init__(**kwargs)\r\n",
    "        self.sample_rate = sample_rate\r\n",
    "        self.fft_size = fft_size\r\n",
    "        self.hop_size = hop_size\r\n",
    "        self.n_mels = n_mels\r\n",
    "        self.f_min = f_min\r\n",
    "        self.f_max = f_max if f_max else sample_rate / 2\r\n",
    "        self.mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\r\n",
    "            num_mel_bins=self.n_mels,\r\n",
    "            num_spectrogram_bins=fft_size // 2 + 1,\r\n",
    "            sample_rate=self.sample_rate,\r\n",
    "            lower_edge_hertz=self.f_min,\r\n",
    "            upper_edge_hertz=self.f_max)\r\n",
    "\r\n",
    "    def build(self, input_shape):\r\n",
    "        self.non_trainable_weights.append(self.mel_filterbank)\r\n",
    "        super(LogMelSpectrogram, self).build(input_shape)\r\n",
    "\r\n",
    "    def call(self, waveforms):\r\n",
    "        \"\"\"Forward pass.\r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        waveforms : tf.Tensor, shape = (None, n_samples)\r\n",
    "            A Batch of mono waveforms.\r\n",
    "        Returns\r\n",
    "        -------\r\n",
    "        log_mel_spectrograms : (tf.Tensor), shape = (None, time, freq, ch)\r\n",
    "            The corresponding batch of log-mel-spectrograms\r\n",
    "        \"\"\"\r\n",
    "        def _tf_log10(x):\r\n",
    "            numerator = tf.math.log(x)\r\n",
    "            denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\r\n",
    "            return numerator / denominator\r\n",
    "\r\n",
    "        def power_to_db(magnitude, amin=1e-16, top_db=80.0):\r\n",
    "            \"\"\"\r\n",
    "            https://librosa.github.io/librosa/generated/librosa.core.power_to_db.html\r\n",
    "            \"\"\"\r\n",
    "            ref_value = tf.reduce_max(magnitude)\r\n",
    "            log_spec = 10.0 * _tf_log10(tf.maximum(amin, magnitude))\r\n",
    "            log_spec -= 10.0 * _tf_log10(tf.maximum(amin, ref_value))\r\n",
    "            log_spec = tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\r\n",
    "\r\n",
    "            return log_spec\r\n",
    "\r\n",
    "        spectrograms = tf.signal.stft(waveforms,\r\n",
    "                                      frame_length=self.fft_size,\r\n",
    "                                      frame_step=self.hop_size,\r\n",
    "                                      pad_end=False)\r\n",
    "\r\n",
    "        magnitude_spectrograms = tf.abs(spectrograms)\r\n",
    "\r\n",
    "        mel_spectrograms = tf.matmul(tf.square(magnitude_spectrograms),\r\n",
    "                                     self.mel_filterbank)\r\n",
    "\r\n",
    "        log_mel_spectrograms = power_to_db(mel_spectrograms)\r\n",
    "\r\n",
    "        # add channel dimension\r\n",
    "        log_mel_spectrograms = tf.expand_dims(log_mel_spectrograms, 3)\r\n",
    "\r\n",
    "        return log_mel_spectrograms\r\n",
    "\r\n",
    "    def get_config(self):\r\n",
    "        config = {\r\n",
    "            'fft_size': self.fft_size,\r\n",
    "            'hop_size': self.hop_size,\r\n",
    "            'n_mels': self.n_mels,\r\n",
    "            'sample_rate': self.sample_rate,\r\n",
    "            'f_min': self.f_min,\r\n",
    "            'f_max': self.f_max,\r\n",
    "        }\r\n",
    "        config.update(super(LogMelSpectrogram, self).get_config())\r\n",
    "\r\n",
    "        return config"
   ],
   "outputs": [],
   "metadata": {
    "id": "p0lSFc5roaSe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CTC\n"
   ],
   "metadata": {
    "id": "6C5AAUQvbiyk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "def ctc_lambda_func(args):\r\n",
    "    y_pred, labels, input_length, label_length = args\r\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ],
   "outputs": [],
   "metadata": {
    "id": "IQIvrmyvjW13"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "def input_lengths_lambda_func(args):\r\n",
    "    input_length = args\r\n",
    "    return tf.cast(tf.math.floor(input_length/hop_size)-1, dtype=\"float32\")"
   ],
   "outputs": [],
   "metadata": {
    "id": "xnn6WhlZ4HJr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "def add_ctc_loss(model_builder):\r\n",
    "    the_labels      = Input(name='the_labels',      shape=(None,), dtype='float32')\r\n",
    "    input_lengths   = Input(name='input_length',    shape=(1,), dtype='float32')\r\n",
    "    label_lengths   = Input(name='label_length',    shape=(1,), dtype='float32')\r\n",
    "\r\n",
    "    input_lengths2 = Lambda(input_lengths_lambda_func)(input_lengths)\r\n",
    "    if model_builder.output_length:\r\n",
    "         output_lengths  = Lambda(model_builder.output_length)(input_lengths2)\r\n",
    "    else:\r\n",
    "         output_lengths  = input_lengths2\r\n",
    "    \r\n",
    "    # CTC loss is implemented in a lambda layer\r\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([model_builder.output, the_labels, output_lengths, label_lengths])\r\n",
    "    model = Model( inputs=[model_builder.input, the_labels, input_lengths, label_lengths],  outputs=loss_out)\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {
    "id": "kdD6eacRjLtx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models"
   ],
   "metadata": {
    "id": "qxIVBU1NkAX5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "def preprocessin_model(sample_rate, fft_size, frame_step, n_mels, mfcc=False):\r\n",
    "\r\n",
    "    input_data = Input(name='input', shape=(None,), dtype=\"float32\")\r\n",
    "    featLayer = LogMelSpectrogram(\r\n",
    "        fft_size=fft_size,\r\n",
    "        hop_size=frame_step,\r\n",
    "        n_mels=n_mels,\r\n",
    "        \r\n",
    "        sample_rate=sample_rate,\r\n",
    "        f_min=0.0,\r\n",
    "        \r\n",
    "        f_max=int(sample_rate / 2)\r\n",
    "    )(input_data)\r\n",
    "    \r\n",
    "    x = BatchNormalization()(featLayer)\r\n",
    "    model = Model(inputs=input_data, outputs=x, name=\"preprocessin_model\")\r\n",
    "\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {
    "id": "38567d3a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "def simple_rnn_model(input_dim, output_dim=224):\r\n",
    "\r\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\r\n",
    "    simp_rnn = GRU(output_dim, return_sequences=True,\r\n",
    "                   implementation=2, name='rnn')(input_data)\r\n",
    "    y_pred = Activation('softmax', name='softmax')(simp_rnn)\r\n",
    "    model = Model(inputs=input_data, outputs=y_pred, name=\"simple_rnn_model\")\r\n",
    "    model.output_length = lambda x: x\r\n",
    "    return model\r\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "3fa7b082"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "def train(model_builder, \r\n",
    "          data_gen,\r\n",
    "          epochs, \r\n",
    "          verbose=1,\r\n",
    "          optimizer=SGD(learning_rate=0.002, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\r\n",
    "          ):    \r\n",
    "              \r\n",
    "    model = add_ctc_loss(model_builder)\r\n",
    "\r\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\r\n",
    "    print(model.summary())\r\n",
    "\r\n",
    "\r\n",
    "    hist = model.fit_generator(generator=data_gen,\r\n",
    "                               epochs=epochs,\r\n",
    "                               verbose=verbose, \r\n",
    "                               use_multiprocessing=False)"
   ],
   "outputs": [],
   "metadata": {
    "id": "2ae84266"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Trainig"
   ],
   "metadata": {
    "id": "GEC6FFW_kayX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "\r\n",
    "sample_rate = 16000\r\n",
    "fft_size = 1024\r\n",
    "frame_step = 512\r\n",
    "n_mels = 128\r\n",
    "\r\n",
    "batch_size = 32\r\n",
    "epochs = 10\r\n",
    "data_len = len(clean_txts)\r\n",
    "output_dim = len(char_map) + 2\r\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "fa980211"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "dg = DataGenerator(sample_audios, clean_txts, batch_size)"
   ],
   "outputs": [],
   "metadata": {
    "id": "a97ffc77"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "preprocess_model = preprocessin_model(sample_rate, fft_size, frame_step, n_mels)\r\n",
    "preprocess_model.summary()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"preprocessin_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "log_mel_spectrogram_2 (LogMe (None, None, 128, 1)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, 128, 1)      4         \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 2\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68e9985a",
    "outputId": "da4cce9b-5dfb-4fa7-b136-e43ca292ad36"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "pip install numpy==1.19.5"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "'C:\\Users\\Maelaf' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "speech_model = simple_rnn_model(n_mels, output_dim)\r\n",
    "speech_model.summary()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"simple_rnn_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 128)]       0         \n",
      "_________________________________________________________________\n",
      "rnn (GRU)                    (None, None, 30)          14400     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 30)          0         \n",
      "=================================================================\n",
      "Total params: 14,400\n",
      "Trainable params: 14,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b8711e1",
    "outputId": "3fa11cb8-25c3-47ae-c068-2461e1662a78"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "def build_model(output_dim, custom_model, preprocess_model, mfcc=False, calc=None):\r\n",
    "\r\n",
    "    input_audios = Input(name='the_input', shape=(None,))\r\n",
    "    pre = preprocess_model(input_audios)\r\n",
    "    pre = tf.squeeze(pre, [3])\r\n",
    "\r\n",
    "    y_pred = custom_model(pre)\r\n",
    "    model = Model(inputs=input_audios, outputs=y_pred, name=\"model_builder\")\r\n",
    "    model.output_length = calc\r\n",
    "\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {
    "id": "62f39784"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "model = build_model(output_dim, speech_model, preprocess_model)\r\n",
    "model.summary()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_builder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "preprocessin_model (Function (None, None, 128, 1)      4         \n",
      "_________________________________________________________________\n",
      "tf.compat.v1.squeeze_2 (TFOp (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_model (Functional (None, None, 30)          14400     \n",
      "=================================================================\n",
      "Total params: 14,404\n",
      "Trainable params: 14,402\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35985dd6",
    "outputId": "733d0188-74b7-47c8-be90-6f797d259227"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "pip install --upgrade tensorflow-estimator==1.19.0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "'C:\\Users\\Maelaf' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "import mlflow"
   ],
   "outputs": [],
   "metadata": {
    "id": "b6b2a7e2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "mlflow.set_experiment('Speech model simple rnn')\r\n",
    "mlflow.tensorflow.autolog()\r\n",
    "hop_size = 512\r\n",
    "train(model, dg, epochs=10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/08/11 19:02:55 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO: 'Speech model simple rnn' does not exist. Creating a new experiment\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Maelaf ES\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1935: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021/08/11 19:02:55 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'ed05f9cd599442fe9a0c9222184710b8', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "preprocessin_model (Functional) (None, None, 128, 1) 4           the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_2 (TFOpLam (None, None, 128)    0           preprocessin_model[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_model (Functional)   (None, None, 30)     14400       tf.compat.v1.squeeze_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           input_length[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           simple_rnn_model[0][0]           \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 14,404\n",
      "Trainable params: 14,402\n",
      "Non-trainable params: 2\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - ETA: 0s - loss: 332.6842WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.5718s vs `on_train_batch_end` time: 0.9460s). Check your callbacks.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.5718s vs `on_train_batch_end` time: 0.9460s). Check your callbacks.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/6 [==============================] - 16s 2s/step - loss: 332.6842\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 4s 607ms/step - loss: 297.6000\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 3s 567ms/step - loss: 270.3237\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 4s 603ms/step - loss: 248.3108\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 3s 564ms/step - loss: 239.0332\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 3s 559ms/step - loss: 238.0268\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 3s 554ms/step - loss: 235.6752\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 4s 613ms/step - loss: 235.4127\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 4s 697ms/step - loss: 235.1330\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 4s 582ms/step - loss: 234.7978\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn, gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\MAELAF~1\\AppData\\Local\\Temp\\tmpfzjw_guh\\model\\data\\model\\assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\MAELAF~1\\AppData\\Local\\Temp\\tmpfzjw_guh\\model\\data\\model\\assets\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989
    },
    "id": "ea406859",
    "outputId": "dedd043a-f789-45c8-b8ba-ec8446721d89"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 2,
  "interpreter": {
   "hash": "c6110edbd6793244b732203b345b097e9a88dc23594c70ff2cfd964a3816e80a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}